0
0:00:00.000 --> 0:00:09.000
大家好,欢迎收听 One More AI,这是一个探讨人工智能技术和应用的播客。

1
0:00:09.000 --> 0:00:17.000
在节目中,我们将会邀请到来自学术界和工业界的各路专家,分享他们的AI实践和行业观点。

2
0:00:17.000 --> 0:00:21.000
如果你也对AI感兴趣,就请跟随我们一起探索吧。

3
0:00:21.000 --> 0:00:23.000
这里是 One More AI。

4
0:00:23.000 --> 0:00:30.000
大家好,欢迎收听 One More AI,我是主持人Kiwi,一个AI领域的投资人。

5
0:00:30.000 --> 0:00:37.000
今天我们很荣幸地邀请到了有着大语言模型训练经验的工程师辛兰,龙老师和产品经理冠叔,

6
0:00:37.000 --> 0:00:44.000
一起来探讨如何训练一个千亿参数量级的大语言模型,以及在此事上的内拆GPT产品。

7
0:00:44.000 --> 0:00:49.000
先请各位嘉宾向听众朋友们打招呼并介绍一下自己吧。

8
0:00:49.000 --> 0:00:58.000
大家好,我是辛兰,过去几年一直在AI公司干各种各样的事情,

9
0:00:58.000 --> 0:01:02.000
跟工程相关的做的都比较多吧。

10
0:01:04.000 --> 0:01:06.000
接下来,龙老师。

11
0:01:08.000 --> 0:01:15.000
大家好,我这边最近几年主要在做一些NLP以及AI方面的一些咨询吧。

12
0:01:15.000 --> 0:01:20.000
然后可能在NLP以及大模型上稍微有一点点经验。

13
0:01:22.000 --> 0:01:25.000
了解,那最后请冠叔来自我介绍一下。

14
0:01:26.000 --> 0:01:33.000
大家好,我是冠叔,我是一个产品经理,是一个野路子AI产品经理,

15
0:01:33.000 --> 0:01:40.000
也是做过非常多的AI业务,对大模型这一块的工作也有一些涉及。

16
0:01:40.000 --> 0:01:45.000
好的,谢谢各位同学,其实我们今天讨论的阵容非常豪华,

17
0:01:45.000 --> 0:01:52.000
大家分别从硬件算法还有产品的视角都有自己的一些看法。

18
0:01:52.000 --> 0:01:57.000
那接下来我们就进入大模型如何去训练的讨论环节。

19
0:01:57.000 --> 0:02:00.000
首先其实想很好奇提个问题,

20
0:02:00.000 --> 0:02:04.000
就是大家眼里的大语言模型该如何去定义呢?

21
0:02:04.000 --> 0:02:10.000
这个要不我先来说吧,从产品经理的视角先给一些定义,

22
0:02:10.000 --> 0:02:14.000
然后一会儿杨大同学可能可以再做一些更正。

23
0:02:14.000 --> 0:02:21.000
对,我这边理解的大模型可能是有这么几方面的定义吧,

24
0:02:21.000 --> 0:02:27.000
首先可能现在我们会更专注于去说这个语言模型,

25
0:02:27.000 --> 0:02:30.000
就是首先它的模型的类型应该属于语言模型,

26
0:02:30.000 --> 0:02:34.000
第二的话就是这个大这个描述,

27
0:02:34.000 --> 0:02:38.000
大的话它其实主要是指模型的体积和参数量,

28
0:02:38.000 --> 0:02:45.000
我自己会认为现在这个阶段的话可能得超过千亿级别的参数

29
0:02:45.000 --> 0:02:47.000
才能称为这个大模型,

30
0:02:47.000 --> 0:02:50.000
不然的话我们就一般就把它叫这个预训练语言模型了。

31
0:02:52.000 --> 0:02:58.000
了解,那这里千亿级别的参数会需要去分这个西数或者成分吗?

32
0:02:58.000 --> 0:03:03.000
这个好像欣然是有这方面的一些经验,

33
0:03:03.000 --> 0:03:05.000
要不他来说一下。

34
0:03:05.000 --> 0:03:11.000
OK,我觉得就说这个西数和成分这个事之前,

35
0:03:11.000 --> 0:03:13.000
先说我定义的大模型吧,

36
0:03:13.000 --> 0:03:18.000
我这边觉得其实在LLP这件事情上,

37
0:03:18.000 --> 0:03:24.000
只要是能够有一定的被称之为现在的永限能力这件事情,

38
0:03:24.000 --> 0:03:28.000
都可以叫这个大预言模型,

39
0:03:28.000 --> 0:03:34.000
大家其实真的不用追求说一定要大到千亿万亿或者多大规模的一个参数量,

40
0:03:34.000 --> 0:03:37.000
其实像最近的一些工作,

41
0:03:37.000 --> 0:03:40.000
它模型也没有大到那种程度,

42
0:03:40.000 --> 0:03:42.000
因为大了真的很难用,

43
0:03:42.000 --> 0:03:45.000
咱们以后聊推理的时候可以聊,

44
0:03:45.000 --> 0:03:47.000
最后实际真正推理的时候,

45
0:03:47.000 --> 0:03:49.000
估计还是会把模型压小了跑的,

46
0:03:49.000 --> 0:03:51.000
所以我觉得只要是有那个预言模型,

47
0:03:51.000 --> 0:03:54.000
让模型压小了跑的,

48
0:03:54.000 --> 0:03:56.000
所以我觉得只要是有那个永限能力,

49
0:03:56.000 --> 0:03:58.000
就是说让你跟他聊天,

50
0:03:58.000 --> 0:04:01.000
觉得他能够理解你的意思,

51
0:04:01.000 --> 0:04:02.000
能跟你交流的,

52
0:04:02.000 --> 0:04:04.000
我觉得就OK了,

53
0:04:04.000 --> 0:04:06.000
参数量不是很重要,

54
0:04:06.000 --> 0:04:10.000
然后至于刚才你说的那个西数还是稠密的,

55
0:04:10.000 --> 0:04:14.000
现阶段一般大家还是都是考虑稠密的吧,

56
0:04:14.000 --> 0:04:18.000
就是西数的更多的是一种优化手段,

57
0:04:18.000 --> 0:04:21.000
还没有太多就是从一开始诞生之初,

58
0:04:21.000 --> 0:04:24.000
就是完全西数的这种预言模型,

59
0:04:24.000 --> 0:04:27.000
当然之前有一个那个MOE,

60
0:04:27.000 --> 0:04:29.000
那个我不知道算不算西数,

61
0:04:29.000 --> 0:04:32.000
那个龙老师可以一会儿说说。

62
0:04:32.000 --> 0:04:35.000
了解,新来的这个定义还是非常吸引的,

63
0:04:35.000 --> 0:04:41.000
其实这个从永限能力的角度去切大这个范畴,

64
0:04:41.000 --> 0:04:44.000
还是一个我觉得很有意思的观点,

65
0:04:44.000 --> 0:04:48.000
那我们在看到这个永限能力何时出现,

66
0:04:48.000 --> 0:04:52.000
会有一个经验的参数数值吗?

67
0:04:52.000 --> 0:04:55.000
之前有篇文章上面具体是讲了说,

68
0:04:55.000 --> 0:04:57.000
他们做了很多实验,

69
0:04:57.000 --> 0:04:58.000
随着这个参数量慢慢追来,

70
0:04:58.000 --> 0:05:00.000
会突然从哪一刻就出现,

71
0:05:00.000 --> 0:05:03.000
当然最近也有一些讲COT的,

72
0:05:03.000 --> 0:05:06.000
就那个逻辑推理的那个链条的那些文章,

73
0:05:06.000 --> 0:05:10.000
这些我作为一个工程人员不太熟悉,

74
0:05:10.000 --> 0:05:12.000
这个龙老师要是知道的话,

75
0:05:12.000 --> 0:05:13.000
一会儿可以跟我说说,

76
0:05:13.000 --> 0:05:20.000
我之前看的反正大概是100个million,

77
0:05:20.000 --> 0:05:24.000
100个,100亿,我之前有看过,

78
0:05:24.000 --> 0:05:26.000
我好像也有印象看过那本,

79
0:05:26.000 --> 0:05:29.000
对,就是到超过100亿就会有能力的影响。

80
0:05:29.000 --> 0:05:31.000
了解,了解,

81
0:05:31.000 --> 0:05:34.000
那么就请我们算法经验很丰富的这个龙老师,

82
0:05:34.000 --> 0:05:37.000
来介绍一下他定义的大模型是什么?

83
0:05:37.000 --> 0:05:43.000
正好这两天其实看到推特上有一个投票,

84
0:05:43.000 --> 0:05:47.000
就是问大家这个多少规模算这个大模型,

85
0:05:47.000 --> 0:05:50.000
其实是一个比较明显的一个分,

86
0:05:50.000 --> 0:05:52.000
是一个分布的,不是一个0到1的,

87
0:05:52.000 --> 0:05:56.000
差不多我记得是90%的人是认为需要到100B里,

88
0:05:56.000 --> 0:06:00.000
也就是千亿对吧,千亿级别,

89
0:06:00.000 --> 0:06:03.000
然后但是我的看法不太一样,

90
0:06:03.000 --> 0:06:07.000
我可能更多是从这个算法角度去看,

91
0:06:07.000 --> 0:06:09.000
或者从算法实践角度去看,

92
0:06:09.000 --> 0:06:11.000
因为我聊到大多数这个算法工程师,

93
0:06:11.000 --> 0:06:16.000
阻碍他们去尝试更大参数量模型的第一个阻碍,

94
0:06:16.000 --> 0:06:18.000
就是有没有模型并行,

95
0:06:18.000 --> 0:06:19.000
就一旦有了模型并行,

96
0:06:19.000 --> 0:06:22.000
这件事情对大多数算法工程师来说,

97
0:06:22.000 --> 0:06:23.000
是一个没有摸过的事情,

98
0:06:23.000 --> 0:06:25.000
难度就会陡增,

99
0:06:25.000 --> 0:06:28.000
然后如果你的训练框架支持模型并行的话,

100
0:06:28.000 --> 0:06:30.000
那实际上后面只是加参数量,

101
0:06:30.000 --> 0:06:32.000
以及加这个算力规模的事情,

102
0:06:32.000 --> 0:06:35.000
所以这个大概会在3B左右吧,

103
0:06:35.000 --> 0:06:37.000
取决于你拿到什么样的机器。

104
0:06:37.000 --> 0:06:38.000
了解了解,

105
0:06:38.000 --> 0:06:42.000
所以其实在大家刚才的讨论当中,

106
0:06:42.000 --> 0:06:48.000
这个5到10B其实是一个在各种维度上,

107
0:06:48.000 --> 0:06:51.000
可能是一个参数量上的一个切分值,

108
0:06:51.000 --> 0:06:54.000
那假设因为我们今天其实想讨论说,

109
0:06:54.000 --> 0:06:57.000
对一个假设是一些新的一些公司,

110
0:06:57.000 --> 0:07:01.000
他想去尝试或者评估自己是否要去训练

111
0:07:01.000 --> 0:07:03.000
一个大模型,

112
0:07:03.000 --> 0:07:06.000
或者说有一些新的团队在考虑我到底是自研,

113
0:07:06.000 --> 0:07:08.000
还是要去这个外采,

114
0:07:08.000 --> 0:07:11.000
那我们今天其实就把我们的这个范畴给定的

115
0:07:11.000 --> 0:07:13.000
稍微给收敛一些,

116
0:07:13.000 --> 0:07:15.000
就假设我们今天就说,

117
0:07:15.000 --> 0:07:17.000
首先是在这个语言模型modality上,

118
0:07:17.000 --> 0:07:19.000
我们是单纯在语言上,

119
0:07:19.000 --> 0:07:23.000
那参数量级假设是一个千亿的参数量级,

120
0:07:23.000 --> 0:07:25.000
加购上我们讨论一个,

121
0:07:25.000 --> 0:07:29.000
因为现在我们大家讨论其实都GPT这个基础之上嘛,

122
0:07:29.000 --> 0:07:32.000
所以我们就讨论是decoder only的这个架构,

123
0:07:32.000 --> 0:07:34.000
那在这几个范畴之内,

124
0:07:34.000 --> 0:07:37.000
如果说我们要去训练一个大模型,

125
0:07:37.000 --> 0:07:40.000
需要多大的算力呢?

126
0:07:42.000 --> 0:07:46.000
我觉得Q刚才这个限制非常好,

127
0:07:46.000 --> 0:07:50.000
就是因为现在其实大家吹的比较火的也是,

128
0:07:50.000 --> 0:07:58.000
因为OpenAI这两年就是把GPT这个结构的模型吹的比较多,

129
0:07:58.000 --> 0:08:02.000
但实际上这种模型的结构很多,

130
0:08:02.000 --> 0:08:06.000
比如说现在其实有很多这种可能模型上加循环了,

131
0:08:06.000 --> 0:08:09.000
那看上去模型参数可能没那么大,

132
0:08:09.000 --> 0:08:12.000
或者它的算力本身结构变得会非常的多,

133
0:08:12.000 --> 0:08:15.000
这些都对于具体后边,

134
0:08:15.000 --> 0:08:18.000
比如说讨论算力量级啊,

135
0:08:18.000 --> 0:08:21.000
或者说怎么训不训得出来啊等等,

136
0:08:21.000 --> 0:08:23.000
这些有很多很多的影响,

137
0:08:23.000 --> 0:08:25.000
我觉得这个未来,

138
0:08:25.000 --> 0:08:28.000
比如说咱们要是看两三年的话,

139
0:08:28.000 --> 0:08:32.000
真不一定非得说大家都得训个GPT这个样子的模型,

140
0:08:32.000 --> 0:08:37.000
从使用角度来说我觉得不一定是最有选项,

141
0:08:37.000 --> 0:08:39.000
因为它挺难训的,

142
0:08:39.000 --> 0:08:42.000
那咱们今天先聊这个吧。

143
0:08:42.000 --> 0:08:43.000
好的。

144
0:08:43.000 --> 0:08:45.000
不过这里我想插一句讨论,

145
0:08:45.000 --> 0:08:48.000
就是其实我跟先人观点是另外一头,

146
0:08:48.000 --> 0:08:51.000
我是比较看好GPT这个架构,

147
0:08:51.000 --> 0:08:54.000
而不看好像T5或者BART这种架构的,

148
0:08:54.000 --> 0:08:57.000
就是你去看GPT-R那篇文章讲的话,

149
0:08:57.000 --> 0:09:02.000
其实它实际上是在顺着两三年前做Meta Learning条线的往下去做,

150
0:09:02.000 --> 0:09:07.000
然后它的结构设计以及任务设计都是非常简单和单一的,

151
0:09:07.000 --> 0:09:09.000
而且就有非常好的扩展性,

152
0:09:09.000 --> 0:09:15.000
而是用T5去做这种Sequence to Sequence的这种预训内任务去做预训内,

153
0:09:15.000 --> 0:09:17.000
然后再迁移到下一个任务上,

154
0:09:17.000 --> 0:09:22.000
总是让人感觉预训内阶段和下一个任务阶段的这两个任务,

155
0:09:22.000 --> 0:09:24.000
是有一个gap的,

156
0:09:24.000 --> 0:09:28.000
这gap总会让你在思考这件事情上会产生一些难度,

157
0:09:28.000 --> 0:09:32.000
所以我还是更看好纯粹的GPT架构。

158
0:09:32.000 --> 0:09:36.000
了解,那我好奇从灌输的角度,

159
0:09:36.000 --> 0:09:40.000
因为刚才龙老师有讲到GPT架构有非常好的延展性,

160
0:09:40.000 --> 0:09:44.000
它的整个网上拓延会有一个更好的基础,

161
0:09:44.000 --> 0:09:46.000
但是从产品经营的角度,

162
0:09:46.000 --> 0:09:51.000
其实我们很多应用端场景现在都是一些很具体的下游理解类任务,

163
0:09:51.000 --> 0:09:59.000
会不会担心如果现阶段就把这种sequence to sequence的这种结构的模型切到了GPT模型之上,

164
0:09:59.000 --> 0:10:03.000
原本的一些性能和参数在短期内会被break掉,

165
0:10:03.000 --> 0:10:07.000
这种产品会有什么样的这些观点吗?

166
0:10:07.000 --> 0:10:11.000
OK,我觉得这其实是一个,

167
0:10:11.000 --> 0:10:16.000
就是我们要用一种发展的眼光来去看这个问题,

168
0:10:16.000 --> 0:10:22.000
就像你提到的,之前可能LOP领域大部分都是偏理解类的,

169
0:10:22.000 --> 0:10:24.000
甚至很多是中间层的这种任务,

170
0:10:24.000 --> 0:10:26.000
在业务里面去发挥作用,

171
0:10:26.000 --> 0:10:32.000
但是它也有自己本身的这种缺陷,

172
0:10:32.000 --> 0:10:36.000
就是每一个任务可能需要去单独的去训练模型,

173
0:10:36.000 --> 0:10:43.000
而且这个使用的过程中也涉及到需要把多种这些算法组合起来去形成一些业务逻辑什么的,

174
0:10:43.000 --> 0:10:47.000
那现在其实我们看到像这个语言模型这样一种方式,

175
0:10:47.000 --> 0:10:50.000
它第一是统一了非常多的任务在一起,

176
0:10:50.000 --> 0:10:53.000
那并且是在训练的这个过程中,

177
0:10:53.000 --> 0:10:57.000
因为不同的类型的这种任务的组合,

178
0:10:57.000 --> 0:11:00.000
让它拥有了像这种Zero-Short,

179
0:11:00.000 --> 0:11:04.000
或者是甚至是逻辑推理的这种能力,

180
0:11:04.000 --> 0:11:07.000
所以从应用的角度上来去看的话,

181
0:11:07.000 --> 0:11:19.000
我会更倾向于未来大家还是会逐渐的甚至是速度很快的迁移到这个生成或者是语言模型这样一个新的技术方式之上,

182
0:11:19.000 --> 0:11:22.000
那这里面其实也会有一个很关键的问题,

183
0:11:22.000 --> 0:11:27.000
就是因为本身模型现阶段它的参数量体积很大,

184
0:11:27.000 --> 0:11:29.000
所以使用的成本相对会高,

185
0:11:29.000 --> 0:11:36.000
所以这件事情它也取决于说未来成本它能够快速的优化到一个什么程度。

186
0:11:36.000 --> 0:11:39.000
了解,既然提到这个成本,

187
0:11:39.000 --> 0:11:41.000
那接下来就是问题了,

188
0:11:41.000 --> 0:11:48.000
我们训练一个千亿量级的这个GPT架构的大语言模型具体需要多大的成本呢?

189
0:11:48.000 --> 0:11:52.000
这个辛莱能跟我们讲解一下吗?

190
0:11:52.000 --> 0:11:57.000
好呀,然后这个我正好今天准备了一些,

191
0:11:57.000 --> 0:12:03.000
就是具体的像这个训练的时候的一些数据啊什么的,

192
0:12:03.000 --> 0:12:04.000
我都是网上查的,

193
0:12:04.000 --> 0:12:06.000
毕竟算法没那么熟悉,

194
0:12:06.000 --> 0:12:09.000
所以我做一些分析,

195
0:12:09.000 --> 0:12:13.000
但是具体的比如说需要有多少计算量等等,

196
0:12:13.000 --> 0:12:18.000
这个大家可以之后以农老师的为准,

197
0:12:18.000 --> 0:12:22.000
就是我觉得在聊这个算力这件事的时候,

198
0:12:22.000 --> 0:12:25.000
我觉得非常有必要先给大家传递一个观点,

199
0:12:25.000 --> 0:12:27.000
就是练大模型这件事情,

200
0:12:27.000 --> 0:12:33.000
它不像是一个简单的说公司里我们堆人直接上,

201
0:12:33.000 --> 0:12:36.000
我们盯着一个指标搞就可以的问题,

202
0:12:36.000 --> 0:12:38.000
它是一个比较大的系统工程,

203
0:12:38.000 --> 0:12:42.000
它是一个类似于火箭发射的大规模的工程问题,

204
0:12:42.000 --> 0:12:45.000
然后这类的大规模的工程问题,

205
0:12:45.000 --> 0:12:50.000
它是其实非常根据大家的这个工程的水平,

206
0:12:50.000 --> 0:12:53.000
而会导致这个成本不一样,

207
0:12:53.000 --> 0:12:56.000
如果工程能力的这个水平高或者低,

208
0:12:56.000 --> 0:12:59.000
有可能会使得这个整个训练成本差一个数量级,

209
0:12:59.000 --> 0:13:02.000
所以我今天就是简化一下这个问题,

210
0:13:02.000 --> 0:13:05.000
就假设已经有一个非常强力的工程团队了,

211
0:13:05.000 --> 0:13:07.000
就是这个工程团队战无不克,

212
0:13:07.000 --> 0:13:11.000
然后所有东西都能发挥到一个各种事情的上限,

213
0:13:11.000 --> 0:13:13.000
那在这个前提之下,

214
0:13:13.000 --> 0:13:15.000
我觉得咱们可以聊算力,

215
0:13:15.000 --> 0:13:16.000
那非常简单,

216
0:13:16.000 --> 0:13:18.000
可以非常简化这个指标,

217
0:13:18.000 --> 0:13:21.000
但实际上其实像互联,

218
0:13:21.000 --> 0:13:24.000
包括这个怎么仿存去优化,

219
0:13:24.000 --> 0:13:27.000
怎么去存储这么一个巨大的一个模型的参数,

220
0:13:27.000 --> 0:13:29.000
这些都有挺多的困难,

221
0:13:29.000 --> 0:13:32.000
所以我觉得咱们聊的时候虽然聊算力,

222
0:13:32.000 --> 0:13:34.000
但是不能简单的微算力对,

223
0:13:34.000 --> 0:13:38.000
就是咱们比如大家都是互联网相关的公司,

224
0:13:38.000 --> 0:13:41.000
用人天算出来的项目就没有不抵累过,

225
0:13:41.000 --> 0:13:47.000
然后之前有一位大佬曾经发过一篇文章,

226
0:13:47.000 --> 0:13:49.000
就是做Chart GPT这一类的东西,

227
0:13:49.000 --> 0:13:52.000
需要我们聪明的去建设整个Infra,

228
0:13:52.000 --> 0:13:55.000
大家有兴趣可以搜一下这篇文章,

229
0:13:55.000 --> 0:13:57.000
如果有需要的话咱们后面再讲,

230
0:13:57.000 --> 0:14:00.000
回到这个算力这件事情,

231
0:14:00.000 --> 0:14:03.000
咱们拿GPT的这个整个发展,

232
0:14:03.000 --> 0:14:04.000
我上网上搜了一下,

233
0:14:04.000 --> 0:14:06.000
Chart GPT 1, 2, 3这三代的发展,

234
0:14:06.000 --> 0:14:12.000
Chart GPT 1的时候参数量是百个million这个级别,

235
0:14:12.000 --> 0:14:16.000
到了GPT 2它一下就翻了100倍,

236
0:14:16.000 --> 0:14:18.000
变成1.5个billion,

237
0:14:18.000 --> 0:14:22.000
到了GPT 3到了175个billion,

238
0:14:22.000 --> 0:14:28.000
其实基本上每一代都是翻个百倍左右的量级,

239
0:14:28.000 --> 0:14:31.000
它的训练Flops就是,

240
0:14:31.000 --> 0:14:34.000
我可能需要给大家说一下Flops是什么,

241
0:14:34.000 --> 0:14:38.000
就是每秒的浮点的运算量,

242
0:14:38.000 --> 0:14:41.000
训练的Flops这件事情,

243
0:14:41.000 --> 0:14:45.000
一般我查到的资料都直接用PFlops,

244
0:14:45.000 --> 0:14:48.000
P就是,这个是多大呢?

245
0:14:48.000 --> 0:14:53.000
那就是2的54方,大概就是多大?

246
0:14:53.000 --> 0:14:55.000
算不明白,不重要,

247
0:14:55.000 --> 0:14:57.000
我后面有一个非常简单的类比,

248
0:14:57.000 --> 0:15:00.000
就是在GPT 1的时候,

249
0:15:00.000 --> 0:15:02.000
如果我们就用A100,

250
0:15:02.000 --> 0:15:05.000
现在比较流行的英伟达的A100这个显卡来算,

251
0:15:05.000 --> 0:15:08.000
那需要0.1个卡年,

252
0:15:08.000 --> 0:15:13.000
也就是说一张卡算0.1年,

253
0:15:13.000 --> 0:15:16.000
那这个计算量差不多不能完成一次训练,

254
0:15:16.000 --> 0:15:18.000
那这其实可以看出来是非常短的,

255
0:15:18.000 --> 0:15:20.000
一个月就算出来了,

256
0:15:20.000 --> 0:15:21.000
如果我们卡多一点,

257
0:15:21.000 --> 0:15:23.000
那可能几天就出来了,

258
0:15:23.000 --> 0:15:26.000
但是如果到了GPT 2,

259
0:15:26.000 --> 0:15:30.000
就已经到了6.81个卡年,

260
0:15:30.000 --> 0:15:32.000
那其实这也还好,

261
0:15:32.000 --> 0:15:35.000
咱们训练的时候都是8卡,

262
0:15:35.000 --> 0:15:36.000
甚至更多卡,

263
0:15:36.000 --> 0:15:39.000
那看起来也是很短时间能训出来,

264
0:15:39.000 --> 0:15:40.000
到了GPT 3呢,

265
0:15:40.000 --> 0:15:43.000
因为它差不多又大了100倍,

266
0:15:43.000 --> 0:15:47.000
大概差不多四五百个卡年,

267
0:15:47.000 --> 0:15:49.000
大概是这么一个量级,

268
0:15:49.000 --> 0:15:52.000
那在这种情况之下,

269
0:15:52.000 --> 0:15:57.000
咱们就可以非常简单的用每张显卡一年,

270
0:15:57.000 --> 0:15:59.000
多少钱这个来算,

271
0:15:59.000 --> 0:16:01.000
咱们简化一下这个问题,

272
0:16:01.000 --> 0:16:03.000
假如今天咱们就要创业,

273
0:16:03.000 --> 0:16:05.000
要算这个价格,

274
0:16:05.000 --> 0:16:07.000
那么既然要创业,

275
0:16:07.000 --> 0:16:09.000
咱们就假定咱们是天选之子,

276
0:16:09.000 --> 0:16:11.000
咱们自己做什么都非常顺,

277
0:16:11.000 --> 0:16:13.000
咱们就可以训出来,

278
0:16:13.000 --> 0:16:16.000
但是实际上大家的训练其实不可能这么一帆风顺,

279
0:16:16.000 --> 0:16:18.000
怎么着得训几轮,

280
0:16:18.000 --> 0:16:20.000
或者说训练训到一半发现不太对,

281
0:16:20.000 --> 0:16:22.000
或者做一些小规模的实验,

282
0:16:22.000 --> 0:16:23.000
但咱们不考虑这么多,

283
0:16:23.000 --> 0:16:25.000
假设就是什么都懂,

284
0:16:25.000 --> 0:16:27.000
一次训练直接开起来,

285
0:16:27.000 --> 0:16:28.000
人呢咱们也不要钱,

286
0:16:28.000 --> 0:16:29.000
不算人的钱,

287
0:16:29.000 --> 0:16:32.000
只算机器的钱,

288
0:16:32.000 --> 0:16:35.000
那现在因为是在国内,

289
0:16:35.000 --> 0:16:37.000
那假设咱们先不买显卡,

290
0:16:37.000 --> 0:16:38.000
咱们是租,

291
0:16:38.000 --> 0:16:41.000
比如说阿里人或者美团人都可以的这个价格,

292
0:16:41.000 --> 0:16:43.000
然后我大概搜了搜,

293
0:16:43.000 --> 0:16:47.000
现在包年的价格其实是一年80万,

294
0:16:47.000 --> 0:16:49.000
8张A100的卡,

295
0:16:49.000 --> 0:16:52.000
那这个我因为以前其实做过这块,

296
0:16:52.000 --> 0:16:54.000
跟他们有过类似的合作,

297
0:16:54.000 --> 0:16:56.000
其实是知道如果关系比较硬,

298
0:16:56.000 --> 0:16:59.000
再加上一次性量总的比较多的话,

299
0:16:59.000 --> 0:17:01.000
其实经常是能够打个半折的,

300
0:17:01.000 --> 0:17:02.000
那我们假定就比较厉害,

301
0:17:02.000 --> 0:17:06.000
我们这8张卡一年就花40万租金,

302
0:17:06.000 --> 0:17:08.000
其他东西全都送我们,

303
0:17:08.000 --> 0:17:10.000
那这样的话相当于一个卡年,

304
0:17:10.000 --> 0:17:11.000
那就是5万块钱,

305
0:17:11.000 --> 0:17:14.000
5万块人民币,

306
0:17:14.000 --> 0:17:16.000
然后最后再假设,

307
0:17:16.000 --> 0:17:18.000
咱们这些假设就得做,

308
0:17:18.000 --> 0:17:21.000
再假设就是咱们可以完美的利用上这些算力,

309
0:17:21.000 --> 0:17:24.000
咱们的代码写得非常的好,

310
0:17:24.000 --> 0:17:25.000
就不会打折,

311
0:17:25.000 --> 0:17:29.000
实际上打折可能再打个半折,

312
0:17:29.000 --> 0:17:32.000
或者打30%的效率都很有可能,

313
0:17:32.000 --> 0:17:34.000
那么在这种情况之下,

314
0:17:34.000 --> 0:17:39.000
咱们一次性能训出来的GPT-1成本大概是几千块钱,

315
0:17:39.000 --> 0:17:43.000
GPT-2大概是30万人民币,

316
0:17:43.000 --> 0:17:48.000
GPT-3这一次训练大概是2400万人民币,

317
0:17:48.000 --> 0:17:50.000
就按2500万人民币算,

318
0:17:50.000 --> 0:17:53.000
大概是这么一个成本,

319
0:17:53.000 --> 0:17:56.000
我觉得就简单来算的话,

320
0:17:56.000 --> 0:17:58.000
可以用这个数字来描述,

321
0:17:58.000 --> 0:18:03.000
我查了查GPT-3OpenAI他们说的,

322
0:18:03.000 --> 0:18:06.000
他们当时是三年前,

323
0:18:06.000 --> 0:18:11.000
那是几百万美金,

324
0:18:11.000 --> 0:18:14.000
差不多,这个价格感觉也对的,

325
0:18:14.000 --> 0:18:16.000
差不太多,现在是便宜了一些,

326
0:18:16.000 --> 0:18:17.000
毕竟已经过了这么多年了,

327
0:18:17.000 --> 0:18:18.000
咱还是用A100,

328
0:18:18.000 --> 0:18:21.000
差不多是这样。

329
0:18:21.000 --> 0:18:22.000
了解,

330
0:18:22.000 --> 0:18:26.000
那也就是说要劝一个接近2000,

331
0:18:26.000 --> 0:18:31.000
就175Billion的GPT-3的量级的模型,

332
0:18:31.000 --> 0:18:35.000
大概需要2000多万人民币左右的价格,

333
0:18:35.000 --> 0:18:40.000
这里其实是把我们整体的GPU的计算,

334
0:18:40.000 --> 0:18:42.000
按100%来计算的,

335
0:18:42.000 --> 0:18:45.000
但事实上其实在大规模的工程训练当中,

336
0:18:45.000 --> 0:18:48.000
我们知道整个GPU的算力的有效利用率,

337
0:18:48.000 --> 0:18:50.000
其实是非常低的,

338
0:18:50.000 --> 0:18:54.000
这里在龙老师有一个经验数值,

339
0:18:54.000 --> 0:18:58.000
大概假设我们用500到1000张卡去做训练的时候,

340
0:18:58.000 --> 0:19:04.000
这个有效算力大概可以提升到一个什么水平呢?

341
0:19:04.000 --> 0:19:07.000
这里面其实有几个比较大的会出现问题点,

342
0:19:07.000 --> 0:19:12.000
先不说我平稳在做forward backward的时候,

343
0:19:12.000 --> 0:19:14.000
算力的使用量,

344
0:19:14.000 --> 0:19:16.000
第一个大问题就是说,

345
0:19:16.000 --> 0:19:19.000
显卡不是像大家比如笔记本里面显卡,

346
0:19:19.000 --> 0:19:21.000
或者台式机显卡那么稳定的,

347
0:19:21.000 --> 0:19:24.000
当你卡到这种几百或者上千级别的时候,

348
0:19:24.000 --> 0:19:28.000
你几乎每天都会遇到有卡直接挂掉,

349
0:19:28.000 --> 0:19:32.000
那我的训练就会被迫暂停,

350
0:19:32.000 --> 0:19:35.000
然后我需要找供应商去换一台机器。

351
0:19:35.000 --> 0:19:39.000
对,我有听团队说他们刚开始训练千亿模型的时候,

352
0:19:39.000 --> 0:19:40.000
GPU打太满,

353
0:19:40.000 --> 0:19:45.000
然后一台A100一天挂两次。

354
0:19:45.000 --> 0:19:47.000
对,所以这个就是第一个比较麻烦的点,

355
0:19:47.000 --> 0:19:50.000
就是你的显卡的质量问题,

356
0:19:50.000 --> 0:19:53.000
比如说你的供应商电力供应不是很稳定,

357
0:19:53.000 --> 0:19:54.000
那就经常挂,

358
0:19:54.000 --> 0:19:59.000
这个时候会导致你不得不接着再训练,

359
0:19:59.000 --> 0:20:01.000
接着再训练就产生另外一个问题,

360
0:20:01.000 --> 0:20:04.000
你多久做一次checkpoint,

361
0:20:04.000 --> 0:20:08.000
如果你一分钟做一次肯定不现实,

362
0:20:08.000 --> 0:20:11.000
因为像这种GBT-3级别的模型,

363
0:20:11.000 --> 0:20:14.000
它可能一个checkpoint除了它的parameter,

364
0:20:14.000 --> 0:20:15.000
还有一些中间状态,

365
0:20:15.000 --> 0:20:19.000
可能就需要比如说两个T甚至到三个T,

366
0:20:19.000 --> 0:20:20.000
我们就按两个T去算,

367
0:20:20.000 --> 0:20:24.000
两个T去算的话,如果你的网络IO又不是很好,

368
0:20:24.000 --> 0:20:26.000
比如你的测评速度不是很好的话,

369
0:20:26.000 --> 0:20:28.000
所以你可能一次checkpoint,

370
0:20:28.000 --> 0:20:30.000
比如说按Handicap数据的话,

371
0:20:30.000 --> 0:20:31.000
可能到几分钟,

372
0:20:31.000 --> 0:20:33.000
如果出问题的话可能十几分钟,

373
0:20:33.000 --> 0:20:34.000
这又是一种浪费,

374
0:20:34.000 --> 0:20:40.000
所以GPU永远是有被浪费的时候,

375
0:20:40.000 --> 0:20:41.000
而且你很难撤走,

376
0:20:41.000 --> 0:20:43.000
完全取决于你使用的硬件的情况,

377
0:20:43.000 --> 0:20:47.000
然后在算法上的话,

378
0:20:47.000 --> 0:20:48.000
其实就还好,

379
0:20:48.000 --> 0:20:51.000
大家会用各种各样的办法尝试做pipeline,

380
0:20:51.000 --> 0:20:54.000
然后把这个显卡给打得很满,

381
0:20:54.000 --> 0:20:58.000
但其实这里面大多数情况下,

382
0:20:58.000 --> 0:20:59.000
Cuda Core是用不满的,

383
0:20:59.000 --> 0:21:02.000
更多是在等各个环节的IO,

384
0:21:02.000 --> 0:21:05.000
比如你的显卡显示单块的IO,

385
0:21:05.000 --> 0:21:07.000
NVLink的IO,Ib网络的IO,

386
0:21:07.000 --> 0:21:09.000
往往是在等IO,

387
0:21:09.000 --> 0:21:12.000
但是如果大家从NVIDIA SMS看的话,

388
0:21:12.000 --> 0:21:13.000
可能感觉是跑满了,

389
0:21:13.000 --> 0:21:14.000
其实并没有。

390
0:21:14.000 --> 0:21:16.000
了解,

391
0:21:16.000 --> 0:21:18.000
所以刚才听到我们在训练过程当中,

392
0:21:18.000 --> 0:21:20.000
一个非常大的瓶颈是在IO,

393
0:21:20.000 --> 0:21:21.000
也就是在通讯上,

394
0:21:21.000 --> 0:21:23.000
这样说起来的话,

395
0:21:23.000 --> 0:21:26.000
我们底层用一个什么样的硬件架构,

396
0:21:26.000 --> 0:21:28.000
对于训练大模型其实至关重要,

397
0:21:28.000 --> 0:21:32.000
那Google它用TPU是不是会非常有优势呢?

398
0:21:32.000 --> 0:21:35.000
我觉得是这样,

399
0:21:35.000 --> 0:21:37.000
关于IO这件事,

400
0:21:37.000 --> 0:21:40.000
它其实跟芯片没关系,

401
0:21:40.000 --> 0:21:42.000
IO这个它就是纯粹的说,

402
0:21:42.000 --> 0:21:48.000
你有多大的内存的通讯带宽,

403
0:21:48.000 --> 0:21:51.000
这个跟选用TPU还是GPU还是什么,

404
0:21:51.000 --> 0:21:52.000
没有关系,

405
0:21:52.000 --> 0:21:54.000
基本上就两套技术,

406
0:21:54.000 --> 0:21:56.000
一个是DDR,

407
0:21:56.000 --> 0:21:58.000
一个是HBM,

408
0:21:58.000 --> 0:22:02.000
其实就是无非是这两套技术怎么组合而已,

409
0:22:02.000 --> 0:22:05.000
然后显卡上用的比较多的都是HBM,

410
0:22:05.000 --> 0:22:09.000
像TPU这边因为他们之前关注的还是成本,

411
0:22:09.000 --> 0:22:11.000
便宜的比较重要,

412
0:22:11.000 --> 0:22:13.000
所以他们用DDR用的比较多,

413
0:22:13.000 --> 0:22:24.000
HBM的带宽一般是几百到几百到TB每秒的速度,

414
0:22:24.000 --> 0:22:26.000
它还是蛮快的,

415
0:22:26.000 --> 0:22:28.000
DDR的话会慢很多,

416
0:22:28.000 --> 0:22:31.000
但是一般会放很多的DDR来把带宽给凑上去,

417
0:22:31.000 --> 0:22:33.000
所以其实在IO这件事上,

418
0:22:33.000 --> 0:22:38.000
用TPU还是用什么用都是类似的,

419
0:22:38.000 --> 0:22:41.000
其实差别不算太大,

420
0:22:41.000 --> 0:22:47.000
但是我觉得可能我这边的认知跟咱们龙老师还不太一样,

421
0:22:47.000 --> 0:22:50.000
就是通过科学的去做排布站的话,

422
0:22:50.000 --> 0:22:53.000
其实卡IO应该没有那么严重,

423
0:22:53.000 --> 0:22:56.000
我们之前做过GPR的训练,

424
0:22:56.000 --> 0:22:58.000
当时其实是通过各种各样的优化,

425
0:22:58.000 --> 0:23:02.000
把整个IO的瓶颈基本都消掉了,

426
0:23:02.000 --> 0:23:04.000
绝大多数情况应该都在计算,

427
0:23:04.000 --> 0:23:11.000
所以这件事其实是花多少精力去做工程优化的一个问题,

428
0:23:11.000 --> 0:23:15.000
我们这边之前花了很长很长时间,

429
0:23:15.000 --> 0:23:19.000
差不多三四个月很多个人一块去搞,

430
0:23:19.000 --> 0:23:22.000
这才把优化给做好,

431
0:23:22.000 --> 0:23:24.000
即便是这样,

432
0:23:24.000 --> 0:23:30.000
我们当时的效率可能也就是整个算力利用率能到四五十,

433
0:23:30.000 --> 0:23:32.000
就大概是这样。

434
0:23:32.000 --> 0:23:35.000
我这里有一个问题其实想讨论的,

435
0:23:35.000 --> 0:23:39.000
刚才其实星人那边有一个假设,

436
0:23:39.000 --> 0:23:41.000
就是我们去估这个成本的时候,

437
0:23:41.000 --> 0:23:44.000
就假设他这个一轮就跑完,

438
0:23:44.000 --> 0:23:49.000
其实我们也看到像OpenAI他去放GDP-3,

439
0:23:49.000 --> 0:23:51.000
当时的那个论文的时候他有提过,

440
0:23:51.000 --> 0:23:55.000
他总共应该是训了四轮,

441
0:23:55.000 --> 0:23:57.000
论文里面说他训了四轮,

442
0:23:57.000 --> 0:24:05.000
那我想我的问题是说是什么原因会导致这个算法训练的过程,

443
0:24:05.000 --> 0:24:08.000
他需要这么多的这个轮次,

444
0:24:08.000 --> 0:24:14.000
以及说从哪些角度可以尽量去减少这个训练的轮次,

445
0:24:14.000 --> 0:24:16.000
因为看起来的话这个轮次这个事情,

446
0:24:16.000 --> 0:24:19.000
他会让成本这件事情成倍的一个增加,

447
0:24:19.000 --> 0:24:27.000
对这一块也想听听两位的意见。

448
0:24:27.000 --> 0:24:29.000
我先说吧,我先说点不专业的,

449
0:24:29.000 --> 0:24:31.000
龙老师一会儿说专业的,

450
0:24:31.000 --> 0:24:35.000
第一个是说大家其实这个一轮,

451
0:24:35.000 --> 0:24:37.000
就是他一轮时间周期太长了,

452
0:24:37.000 --> 0:24:40.000
训可能上个月的这个时间,

453
0:24:40.000 --> 0:24:42.000
而且非常大规模的这个成本,

454
0:24:42.000 --> 0:24:46.000
所以实际上大家并不是说按一个按钮开始,

455
0:24:46.000 --> 0:24:48.000
然后等他训完,

456
0:24:48.000 --> 0:24:51.000
大多数其实会不断的去监控去看Action的怎么样,

457
0:24:51.000 --> 0:24:56.000
这些模型有很多有理论去教会你说怎么三岁看老,

458
0:24:56.000 --> 0:25:01.000
或者在一个更小规模的模型上去验证你的一些设定是不是好,

459
0:25:01.000 --> 0:25:03.000
所以如果我没记错的话,

460
0:25:03.000 --> 0:25:05.000
OpenAI训这些模型的时候,

461
0:25:05.000 --> 0:25:09.000
他们也都是说我小规模的先跑一跑看一看,

462
0:25:09.000 --> 0:25:13.000
比如跑1%的步训练的轮数,

463
0:25:13.000 --> 0:25:15.000
先看一看这个模型的状态是不是OK,

464
0:25:15.000 --> 0:25:17.000
如果不OK的我赶紧杀掉,

465
0:25:17.000 --> 0:25:20.000
或者回滚一段时间再重新训练之类的,

466
0:25:20.000 --> 0:25:28.000
所以其实真正去训练应该像GBT-3这种就是完整训一大轮,

467
0:25:28.000 --> 0:25:32.000
但是前面可能不断的做了很多小规模的实验,

468
0:25:32.000 --> 0:25:37.000
所以这其实还产生了另外一个潜在的成本,

469
0:25:37.000 --> 0:25:41.000
就是如果我上来就把所有的机器都堆在这,

470
0:25:41.000 --> 0:25:43.000
比如我买机器,

471
0:25:43.000 --> 0:25:45.000
或者我租机器一下租了好几千块卡,

472
0:25:45.000 --> 0:25:49.000
租放在这,然后发现早期就在疯狂的做实验,

473
0:25:49.000 --> 0:25:53.000
那其实这些显卡在早期并没有办法这么有效的利用起来,

474
0:25:53.000 --> 0:25:55.000
那可能在不断的做小规模实验,

475
0:25:55.000 --> 0:26:00.000
所以这一部分其实也会有相当长的成本,

476
0:26:00.000 --> 0:26:03.000
可能前三个月都在各种倒过,

477
0:26:03.000 --> 0:26:06.000
而不是真的说一把速直接开始训练。

478
0:26:06.000 --> 0:26:10.000
这符合龙老师的经验吗?

479
0:26:10.000 --> 0:26:12.000
这经验总结其实挺全的,

480
0:26:12.000 --> 0:26:15.000
然后我就补充一小点,

481
0:26:15.000 --> 0:26:19.000
大家发现很多小规模的实验都挺好的,

482
0:26:19.000 --> 0:26:24.000
但就是一到100B级别就会发现各种loss的不收敛,

483
0:26:24.000 --> 0:26:27.000
或者说训练到一半的时候loss突然就猛增,

484
0:26:27.000 --> 0:26:30.000
就飞掉了,然后后面再也没法收敛,

485
0:26:30.000 --> 0:26:34.000
在Funkface以及在Meta的实验当中都观察到这个现象,

486
0:26:34.000 --> 0:26:36.000
最后大家可能就是回退几步,

487
0:26:36.000 --> 0:26:38.000
或者扔掉这部分数据,

488
0:26:38.000 --> 0:26:41.000
然后接着往前走。

489
0:26:41.000 --> 0:26:44.000
但是我有在一些分析文章中看到,

490
0:26:44.000 --> 0:26:46.000
就是回退的次数过多,

491
0:26:46.000 --> 0:26:51.000
其实也会导致最后的模型效果不如预期,

492
0:26:51.000 --> 0:26:58.000
龙老师有在实际的训练过程中遇到类似的情况吗?

493
0:26:58.000 --> 0:27:00.000
这个没有,这个没有,

494
0:27:00.000 --> 0:27:03.000
其实我也很好奇到底怎么一回事,

495
0:27:03.000 --> 0:27:05.000
因为Funkface那边是一个,

496
0:27:05.000 --> 0:27:08.000
或者微观去看了一下其中一次现象,

497
0:27:08.000 --> 0:27:12.000
在数据整理过程当中发现了一条样本,

498
0:27:12.000 --> 0:27:15.000
这条样本可能大概是上万个字符,

499
0:27:15.000 --> 0:27:18.000
然后这里面所有字符都是一个正写杠还是反写杠,

500
0:27:18.000 --> 0:27:22.000
记不清了,导致它的T2直接就乱掉了,

501
0:27:22.000 --> 0:27:24.000
然后后面再也没法收敛,

502
0:27:24.000 --> 0:27:27.000
后面他们的策略就是找到这种脏数据就给删掉,

503
0:27:27.000 --> 0:27:29.000
然后就找一个好一些的。

504
0:27:29.000 --> 0:27:34.000
另外还有一个就是说FP32和FP16还有BF16这个问题,

505
0:27:34.000 --> 0:27:37.000
其实大家好像还没有太好的结论,

506
0:27:37.000 --> 0:27:39.000
FP32大家肯定训练的挺好的,

507
0:27:39.000 --> 0:27:41.000
但是太贵了嘛,

508
0:27:41.000 --> 0:27:44.000
然后Hunkface这边选择BF16稍微好一点,

509
0:27:44.000 --> 0:27:46.000
然后Meta是FP16也搞定了,

510
0:27:46.000 --> 0:27:48.000
所以这也是一个问题。

511
0:27:48.000 --> 0:27:52.000
了解,所以不一定说必须要用FP16,

512
0:27:52.000 --> 0:27:56.000
其实这个F16也能去券千亿的大模型,

513
0:27:56.000 --> 0:27:59.000
并且得到一个收敛的模型是吧?

514
0:27:59.000 --> 0:28:03.000
这BF16,我更欣赏BF16吧,

515
0:28:03.000 --> 0:28:07.000
因为首先看Google这边做T5,

516
0:28:07.000 --> 0:28:09.000
一直拿BF16去做的,

517
0:28:09.000 --> 0:28:11.000
看起来会比较稳定,

518
0:28:11.000 --> 0:28:13.000
然后Hunkface这边去试了一圈以后,

519
0:28:13.000 --> 0:28:15.000
也是决定BF16更好收敛。

520
0:28:15.000 --> 0:28:17.000
了解,了解。

521
0:28:17.000 --> 0:28:19.000
OK。

522
0:28:19.000 --> 0:28:22.000
这个我知道一个非常有意思的事情是,

523
0:28:22.000 --> 0:28:26.000
我们之前信GPTR的时候的感觉也是这样,

524
0:28:26.000 --> 0:28:29.000
就是用FP16它其实速度快了很多,

525
0:28:29.000 --> 0:28:31.000
但是就需要派一个人,

526
0:28:31.000 --> 0:28:34.000
叫崩不崩,就是观察员,

527
0:28:34.000 --> 0:28:37.000
他就每天看着这个模型,

528
0:28:37.000 --> 0:28:39.000
突然看这个模型,

529
0:28:39.000 --> 0:28:41.000
就是它的精度爆了,

530
0:28:41.000 --> 0:28:43.000
赶紧停掉重启,

531
0:28:43.000 --> 0:28:47.000
我们之前就有这么一个人一直盯着它,

532
0:28:47.000 --> 0:28:50.000
整个训练过程中每天都在重启,

533
0:28:50.000 --> 0:28:53.000
这是一个非常常态的一个东西,

534
0:28:53.000 --> 0:28:55.000
所以其实整个训练过程中,

535
0:28:55.000 --> 0:28:58.000
看上去可能我优化了很多很多的东西,

536
0:28:58.000 --> 0:29:01.000
所以这个大致会达到非常的猛。

537
0:29:01.000 --> 0:29:04.000
了解,这个用人盯它崩不崩,

538
0:29:04.000 --> 0:29:06.000
没有工具可以代替实现吗?

539
0:29:06.000 --> 0:29:08.000
类似像Base and Basis,

540
0:29:08.000 --> 0:29:10.000
Weights and Basis这样的。

541
0:29:10.000 --> 0:29:13.000
就是基本的是没什么问题的,

542
0:29:13.000 --> 0:29:16.000
就是重点是崩完了之后,

543
0:29:16.000 --> 0:29:18.000
他得去看历史的数据,

544
0:29:18.000 --> 0:29:20.000
我怎么往前滚一滚,

545
0:29:20.000 --> 0:29:24.000
那这些东西现在并没有成为一个非常有效的经验,

546
0:29:24.000 --> 0:29:27.000
所以还是大家怎么说,

547
0:29:27.000 --> 0:29:31.000
还是一个非常专业的人在那盯着才行,

548
0:29:31.000 --> 0:29:35.000
也许等未来这个东西慢慢的越来越多人在训练,

549
0:29:35.000 --> 0:29:38.000
那可能它会形成一套自动化的工具,

550
0:29:38.000 --> 0:29:40.000
但现阶段还不行。

551
0:29:40.000 --> 0:29:43.000
这个人会有点像老中医的感觉是吗?

552
0:29:43.000 --> 0:29:45.000
就是给你号号脉,

553
0:29:45.000 --> 0:29:50.000
号完脉之后大概知道我要不要按这个按钮。

554
0:29:50.000 --> 0:29:53.000
对,因为他很多时候,

555
0:29:53.000 --> 0:29:56.000
他崩不是这么简单的一句话崩,

556
0:29:56.000 --> 0:29:59.000
他得看一看说我怎么突然NN了,

557
0:29:59.000 --> 0:30:02.000
到底是有一条脏数据NN了,

558
0:30:02.000 --> 0:30:04.000
还是就是不知道怎么回事他就NN了,

559
0:30:04.000 --> 0:30:06.000
我回退多少等等,

560
0:30:06.000 --> 0:30:08.000
这个都很玄妙,

561
0:30:08.000 --> 0:30:11.000
这个其实是做实验的一部分,

562
0:30:11.000 --> 0:30:14.000
它并不是单纯的说就是不太对,

563
0:30:14.000 --> 0:30:17.000
我点一下重启就好了,这么简单的一个问题。

564
0:30:17.000 --> 0:30:19.000
我多问一下,

565
0:30:19.000 --> 0:30:25.000
我很好奇这个角色他通常是一个偏工程的一个人员能去做,

566
0:30:25.000 --> 0:30:27.000
还是一个算法研究员,

567
0:30:27.000 --> 0:30:30.000
还是得两者兼具才能去做这个事情?

568
0:30:30.000 --> 0:30:35.000
我的经验是肯定得两者兼具,

569
0:30:35.000 --> 0:30:38.000
当然算法的属性会多一些,

570
0:30:38.000 --> 0:30:41.000
因为绝大多数的问题都是算法上的问题,

571
0:30:41.000 --> 0:30:45.000
工程上的问题相对来说就一般坏的都比较彻底,

572
0:30:45.000 --> 0:30:48.000
就比较容易判断说这个不对了。

573
0:30:48.000 --> 0:30:54.000
了解,刚才其实我们在讨论这个算力成本的时候,

574
0:30:54.000 --> 0:30:59.000
其实都是基于GPT-3的实验在讨论,

575
0:30:59.000 --> 0:31:04.000
但事实上前段时间Meta不是发布了这个LAM13B的模型吗?

576
0:31:04.000 --> 0:31:08.000
我们发现这个百亿模型其实也可以达到一个很好的效果,

577
0:31:08.000 --> 0:31:10.000
但是我看LAM的文章里面有提到,

578
0:31:10.000 --> 0:31:18.000
就是他训练的token数是远高于之前类似于像GPT-3的训练的token数的,

579
0:31:18.000 --> 0:31:21.000
所以其实这里就会涉及到有一个问题,

580
0:31:21.000 --> 0:31:25.000
就是我可以选择在前期训练的时候,

581
0:31:25.000 --> 0:31:30.000
我把成本压一压,比如说我训练的数据量和token数,

582
0:31:30.000 --> 0:31:32.000
我去进行一些限制,

583
0:31:32.000 --> 0:31:37.000
但是我最终可能在目标的效果下,

584
0:31:37.000 --> 0:31:39.000
我得到了一个千亿量级的模型。

585
0:31:39.000 --> 0:31:43.000
另外一种选择是我前期的fixed投入,

586
0:31:43.000 --> 0:31:44.000
就是固定投入非常高,

587
0:31:44.000 --> 0:31:47.000
我可能把token数量和数据量都增加,

588
0:31:47.000 --> 0:31:49.000
然后可能用一种overchain的方式,

589
0:31:49.000 --> 0:31:53.000
但是我可能得到了一个参数量级更小的,

590
0:31:53.000 --> 0:31:56.000
可以达到我们效果预期的模型,

591
0:31:56.000 --> 0:32:00.000
但换来的就是我的influence的成本可以降低很多。

592
0:32:00.000 --> 0:32:03.000
这个我不知道从三位的经验上来说,

593
0:32:03.000 --> 0:32:07.000
我们会如何权衡这之间的数值呢?

594
0:32:10.000 --> 0:32:12.000
要不我先说一下,

595
0:32:13.000 --> 0:32:16.000
首先MAC这篇就是LAM,

596
0:32:16.000 --> 0:32:17.000
我发音可能是LAMA,

597
0:32:17.000 --> 0:32:19.000
当然可能不太一样。

598
0:32:19.000 --> 0:32:22.000
这篇文章我觉得最主要的一个启示,

599
0:32:22.000 --> 0:32:24.000
或者说它主要的一个贡献,

600
0:32:24.000 --> 0:32:29.000
就是在花相同的预算的情况下,

601
0:32:29.000 --> 0:32:31.000
可能能达到类似或更好的效果,

602
0:32:31.000 --> 0:32:34.000
而这件事情跟参数量不完全相关,

603
0:32:34.000 --> 0:32:39.000
但又因为它的这次实验其实缺少一个很严格的,

604
0:32:39.000 --> 0:32:41.000
跟GP30可对比的一个东西,

605
0:32:41.000 --> 0:32:42.000
毕竟两家单独做的,

606
0:32:42.000 --> 0:32:43.000
很多细节会不一样,

607
0:32:43.000 --> 0:32:46.000
所以只能说大家现在观察到这么一个现象,

608
0:32:46.000 --> 0:32:49.000
比如说我只用不到100B的参数量,

609
0:32:49.000 --> 0:32:54.000
然后生产能量把从300B的token提到1.4T的token,

610
0:32:54.000 --> 0:32:58.000
这样去做的话也许会达到类似的效果,

611
0:32:58.000 --> 0:33:01.000
但是会不会对其他各种细节,

612
0:33:01.000 --> 0:33:05.000
比如各种各样细节的评测一下任务的效果有什么影响,

613
0:33:05.000 --> 0:33:07.000
这件事情我也在观察,

614
0:33:07.000 --> 0:33:10.000
因为好多人去申请了之下,

615
0:33:10.000 --> 0:33:12.000
这个模型其实一直在拖,

616
0:33:12.000 --> 0:33:14.000
前两天刚开放一批下载,

617
0:33:14.000 --> 0:33:16.000
这批模型放出来之后,

618
0:33:16.000 --> 0:33:17.000
然后各家去做评测,

619
0:33:17.000 --> 0:33:19.000
然后去做各种各样的任务,

620
0:33:19.000 --> 0:33:21.000
才知道这到底会不会有问题,

621
0:33:21.000 --> 0:33:24.000
否则的话我现在可能更倾向于保守的,

622
0:33:24.000 --> 0:33:26.000
还是沿着这个GP30这个路线去走。

623
0:33:28.000 --> 0:33:29.000
了解了解,

624
0:33:29.000 --> 0:33:34.000
那现阶段其实我们都知道A100的,

625
0:33:34.000 --> 0:33:36.000
甚至未来H100的这个采购,

626
0:33:36.000 --> 0:33:39.000
在中国大陆的范围内其实会受到很多限制,

627
0:33:39.000 --> 0:33:47.000
可能接下来大家不得不在有限的硬件的情况下去选择A800去训练,

628
0:33:47.000 --> 0:33:49.000
那我想请问一下,

629
0:33:49.000 --> 0:33:53.000
当我们去用A100,A800或者未来H100去训练的时候,

630
0:33:53.000 --> 0:33:55.000
具体会有哪些差异呢?

631
0:33:58.000 --> 0:33:59.000
这个新来的,

632
0:33:59.000 --> 0:34:00.000
我说一说吧,

633
0:34:02.000 --> 0:34:06.000
我觉得先说一下这个A800这个差别吧,

634
0:34:06.000 --> 0:34:09.000
它最大的差别其实就是算力都一样,

635
0:34:09.000 --> 0:34:11.000
只是它在通信的时候,

636
0:34:11.000 --> 0:34:13.000
就是卡之间的通信带宽,

637
0:34:13.000 --> 0:34:16.000
从600GB每秒变成400GB每秒,

638
0:34:16.000 --> 0:34:19.000
这个带宽首先是非常离谱,

639
0:34:19.000 --> 0:34:23.000
这个跟大家平常日用的感觉是非常不一样的,

640
0:34:23.000 --> 0:34:25.000
就是大家平常上网的带宽,

641
0:34:25.000 --> 0:34:27.000
那无非是120MB每秒,

642
0:34:27.000 --> 0:34:29.000
就是已经是千兆宽带了,

643
0:34:29.000 --> 0:34:34.000
那这个速度是大家平时上网的这个速度的上千倍了,

644
0:34:34.000 --> 0:34:39.000
所以这个本身是一个非常巨大的通信带宽,

645
0:34:39.000 --> 0:34:42.000
在这个原本非常离谱的带宽上打了点折,

646
0:34:42.000 --> 0:34:44.000
从600GB变成400GB了,

647
0:34:44.000 --> 0:34:46.000
有些人会比较悲观,

648
0:34:46.000 --> 0:34:47.000
就是说哇,

649
0:34:47.000 --> 0:34:51.000
我这个本来我模型训练就是一个多机的训练,

650
0:34:51.000 --> 0:34:54.000
那我多机训练的这个通信带宽被突然砍掉了,

651
0:34:54.000 --> 0:34:55.000
从600GB到400GB,

652
0:34:55.000 --> 0:34:56.000
一下掉了三分之一呢,

653
0:34:56.000 --> 0:34:57.000
可能会比较严重,

654
0:34:57.000 --> 0:35:03.000
但是我觉得其实影响还很类似,

655
0:35:03.000 --> 0:35:05.000
其实这两者问题不大,

656
0:35:05.000 --> 0:35:08.000
因为它们其实在计算上是类似的,

657
0:35:08.000 --> 0:35:11.000
就是没有什么区别,

658
0:35:11.000 --> 0:35:14.000
只是通信带宽这块从600到400,

659
0:35:14.000 --> 0:35:15.000
但是呢,

660
0:35:15.000 --> 0:35:18.000
咱们实际上真正在训练的时候,

661
0:35:18.000 --> 0:35:23.000
咱们玩的游戏并不是一个单机内几张显卡的一个通信游戏,

662
0:35:23.000 --> 0:35:30.000
而是一个上百上千甚至恨不得有些公司是用上万块显卡来做计算的这么一个游戏,

663
0:35:30.000 --> 0:35:32.000
那这么大规模的时候,

664
0:35:32.000 --> 0:35:35.000
通信的主要成本是机器间的通讯,

665
0:35:35.000 --> 0:35:38.000
机器间的通信现在还比较怎么说呢,

666
0:35:38.000 --> 0:35:43.000
就是这个带宽还是在就是200GB小币的,

667
0:35:43.000 --> 0:35:45.000
就是小币就是会除8,

668
0:35:45.000 --> 0:35:46.000
这么一个带宽,

669
0:35:46.000 --> 0:35:49.000
那一般现在都大家花钱会花的比较凶,

670
0:35:49.000 --> 0:35:52.000
可能会差四块网卡一起用,

671
0:35:52.000 --> 0:35:56.000
那机器间的通讯带宽也不过是100GB每秒,

672
0:35:56.000 --> 0:35:59.000
所以这块其实会发现一个问题,

673
0:35:59.000 --> 0:36:00.000
就是机器内的这个通信,

674
0:36:00.000 --> 0:36:03.000
它跌的一点其实问题不大,

675
0:36:03.000 --> 0:36:09.000
因为机器间的那个通讯带宽低是整个大规模病情训练的最大瓶颈,

676
0:36:09.000 --> 0:36:12.000
所以这件事呢肯定是会有影响的,

677
0:36:12.000 --> 0:36:17.000
就是相当于别人非常容易就能把机器内的通讯做好,

678
0:36:17.000 --> 0:36:20.000
但是如果我们用A800的话,

679
0:36:20.000 --> 0:36:22.000
那会使得这个通讯带宽低一点,

680
0:36:22.000 --> 0:36:23.000
那我们需要好好走,

681
0:36:23.000 --> 0:36:28.000
需要更多的工程人员去精心的去调这个病情策略,

682
0:36:28.000 --> 0:36:30.000
刚才咱们龙老师也说了,

683
0:36:30.000 --> 0:36:33.000
就是核心的一个难点其实是模型病情,

684
0:36:33.000 --> 0:36:39.000
那其实就相当于是说我机器内的时候把模型病情做得再更好一些,

685
0:36:39.000 --> 0:36:41.000
我专门弄一个团队去优化这个分布式训练,

686
0:36:41.000 --> 0:36:46.000
其实是能够把这一个200G的差别给掩藏掉的,

687
0:36:46.000 --> 0:36:50.000
但这件事对于国内追赶国外是不是有一些影响,

688
0:36:50.000 --> 0:36:52.000
肯定有,就相当于多了一个阻碍嘛,

689
0:36:52.000 --> 0:36:54.000
只是说现在这个阻碍不会要了你的命,

690
0:36:54.000 --> 0:36:56.000
但是会很烦,

691
0:36:56.000 --> 0:36:58.000
那所以短期来看,

692
0:36:58.000 --> 0:37:01.000
其实这个影响我觉得还挺有限的,

693
0:37:01.000 --> 0:37:05.000
就是A800,A100用哪个其实都还好,

694
0:37:05.000 --> 0:37:09.000
相当大的一个坑的地方可能就在于成本会变得很高,

695
0:37:09.000 --> 0:37:12.000
因为A800的价格其实比A100还高,

696
0:37:12.000 --> 0:37:14.000
就即便它的性能差,

697
0:37:14.000 --> 0:37:15.000
它还比它价格还高,

698
0:37:15.000 --> 0:37:16.000
这个非常的离谱,

699
0:37:16.000 --> 0:37:18.000
它现在是个特供版嘛,

700
0:37:18.000 --> 0:37:21.000
但长期来看可能会非常可怕,

701
0:37:21.000 --> 0:37:24.000
因为现在咱们大家在盯的东西都是A100,

702
0:37:24.000 --> 0:37:27.000
那A100可是两年前发布的呀,

703
0:37:27.000 --> 0:37:30.000
我不太确定是不是两年前还是三年前,

704
0:37:30.000 --> 0:37:32.000
就是这个已经发布很久了,

705
0:37:32.000 --> 0:37:35.000
H100早就已经说要发布了,

706
0:37:35.000 --> 0:37:37.000
但是一直还没有,

707
0:37:37.000 --> 0:37:38.000
就用的人还不太多,

708
0:37:38.000 --> 0:37:42.000
现在国外已经在有人慢慢开始用H100在训练了,

709
0:37:42.000 --> 0:37:45.000
那么H100的时候它的通信带宽会上升到什么呢,

710
0:37:45.000 --> 0:37:47.000
上升到900GB,

711
0:37:47.000 --> 0:37:50.000
那我们如果还是400,

712
0:37:50.000 --> 0:37:51.000
它是900,

713
0:37:51.000 --> 0:37:53.000
那这是一个非常猛的,

714
0:37:53.000 --> 0:37:55.000
然后更可怕的是什么呢,

715
0:37:55.000 --> 0:37:56.000
它的算力,

716
0:37:56.000 --> 0:38:04.000
H100的算力是它的F16和BF16已经到达了900多TFLOPs,

717
0:38:04.000 --> 0:38:09.000
而咱们的A100、A800还在100多、300多的这个级别,

718
0:38:09.000 --> 0:38:11.000
那一下高了,

719
0:38:11.000 --> 0:38:14.000
当然得看具体的设置,

720
0:38:14.000 --> 0:38:15.000
高了很多,

721
0:38:15.000 --> 0:38:16.000
高了四五倍,

722
0:38:16.000 --> 0:38:17.000
差这么多,

723
0:38:17.000 --> 0:38:20.000
那这件事在长期来说会非常可怕,

724
0:38:20.000 --> 0:38:22.000
如果仍然是处于禁运的状态,

725
0:38:22.000 --> 0:38:25.000
那么这个算力差距就差了六倍,

726
0:38:25.000 --> 0:38:28.000
通信带宽也差了两倍,

727
0:38:28.000 --> 0:38:30.000
那这个其实是非常可怕的,

728
0:38:30.000 --> 0:38:39.000
然后现在美国的半导体禁令是说性能和通信带宽同时大于A100的芯片是不能够禁运的,

729
0:38:39.000 --> 0:38:42.000
那是不能够出口给中国的,

730
0:38:42.000 --> 0:38:46.000
那么未来H100会不会出一个性能能不能超越A100,

731
0:38:46.000 --> 0:38:51.000
但是通信带宽进一步砍到比A100还热的版本的H100,

732
0:38:51.000 --> 0:38:55.000
就假设出了会很畸形,

733
0:38:55.000 --> 0:38:59.000
而且就是前面说的那个通信带宽带来的困难会更大,

734
0:38:59.000 --> 0:39:05.000
就这一块我觉得还是问题还是很严重的。

735
0:39:05.000 --> 0:39:08.000
这里我有一个问题,

736
0:39:08.000 --> 0:39:12.000
就是我可能也是从我们听众的这个视角来去问,

737
0:39:12.000 --> 0:39:17.000
那假使说我们的这种分布式训练的技术,

738
0:39:17.000 --> 0:39:25.000
包括工程方面的一些经验都是基于一个落后的版本的显卡来去做的,

739
0:39:25.000 --> 0:39:30.000
那当我的这个卡有一天升级了,

740
0:39:30.000 --> 0:39:32.000
就是我能用上更好的卡的时候,

741
0:39:32.000 --> 0:39:34.000
那我积累的这些工程的经验,

742
0:39:34.000 --> 0:39:36.000
这些分布式的经验,

743
0:39:36.000 --> 0:39:40.000
它是可以有多大比例是能够被附庸过来?

744
0:39:40.000 --> 0:39:47.000
这个比例很玄学,因为这个其实是知识,

745
0:39:47.000 --> 0:39:51.000
可能大概有一半吧,

746
0:39:51.000 --> 0:39:53.000
但是如果一直在这个低端卡,

747
0:39:53.000 --> 0:39:58.000
比如说我之前我们团队训练GPTR的时候的经验就是,

748
0:39:58.000 --> 0:40:00.000
我们当时是拿2080Ti训练的,

749
0:40:00.000 --> 0:40:02.000
这个龙老师应该有概念,

750
0:40:02.000 --> 0:40:04.000
这个是一个多么可怕的事情,

751
0:40:04.000 --> 0:40:07.000
我们当时用2080Ti训GPTR,

752
0:40:07.000 --> 0:40:09.000
我们动用了512张卡,

753
0:40:09.000 --> 0:40:12.000
那么如果当时我们能换用A100训,

754
0:40:12.000 --> 0:40:13.000
我们需要多少呢?

755
0:40:13.000 --> 0:40:15.000
我们只需要两台机器就OK了,

756
0:40:15.000 --> 0:40:17.000
那这个差别是巨大的,

757
0:40:17.000 --> 0:40:21.000
那这里面所有之前我们精心调教的一些分布式的经验,

758
0:40:21.000 --> 0:40:27.000
怎么把模型切得碎碎的在这些显卡上并行的去跑等等这些事情,

759
0:40:27.000 --> 0:40:30.000
这个用处都没了,

760
0:40:30.000 --> 0:40:34.000
所以理念仍然是有效的,

761
0:40:34.000 --> 0:40:36.000
就是分布式的这一块的理念,

762
0:40:36.000 --> 0:40:38.000
这些知识,包括这些经验一定是有用的,

763
0:40:38.000 --> 0:40:42.000
但是真的能直接transfer过来用的应该不太多,

764
0:40:42.000 --> 0:40:50.000
所以什么东西都在这种10倍的量级的差别下会被磨炸,

765
0:40:50.000 --> 0:40:51.000
灰飞烟灭。

766
0:40:51.000 --> 0:40:55.000
所以可以理解为是这些基本的方法,

767
0:40:55.000 --> 0:40:58.000
还有这些思想是可以继承的,

768
0:40:58.000 --> 0:41:02.000
但是实操层面的很多技术可能就会失效了,

769
0:41:02.000 --> 0:41:07.000
我觉得这很像当年造原子弹的时候,

770
0:41:07.000 --> 0:41:10.000
就是我们用算盘来去打一些数据,

771
0:41:10.000 --> 0:41:15.000
用算盘去替代或者说是去代替计算机的这种方式,

772
0:41:15.000 --> 0:41:17.000
就是我知道怎么去算,

773
0:41:17.000 --> 0:41:19.000
但是我就是会算得很慢。

774
0:41:19.000 --> 0:41:24.000
我觉得可能有另外一种比喻方式,

775
0:41:24.000 --> 0:41:31.000
就是早些年不管是中国用算盘还是国外最早用IBM的那种什么齿轮机做计算的时候,

776
0:41:31.000 --> 0:41:35.000
那个时候是有一套非常纪律严明的,

777
0:41:35.000 --> 0:41:37.000
说我有30个计算人员,

778
0:41:37.000 --> 0:41:39.000
他们怎么彼此之间协作,

779
0:41:39.000 --> 0:41:40.000
怎么通信,

780
0:41:40.000 --> 0:41:42.000
谁应该把指示怎么交给谁的这种规范,

781
0:41:42.000 --> 0:41:44.000
使得他们能够高效的做计算,

782
0:41:44.000 --> 0:41:45.000
但是当你有一台计算机,

783
0:41:45.000 --> 0:41:47.000
你可能就不用做这么麻烦了,

784
0:41:47.000 --> 0:41:49.000
你的管理方式就不一样了。

785
0:41:49.000 --> 0:41:52.000
所以当这个算力差的越来越多之后,

786
0:41:52.000 --> 0:41:58.000
这个一定会使得你的一些使用的方式知识都变得比较多,

787
0:41:58.000 --> 0:42:01.000
但你说就我在管理这件事上,

788
0:42:01.000 --> 0:42:05.000
比如说我就是30个计算模块并行的去执行,

789
0:42:05.000 --> 0:42:08.000
那这30个计算模块到底是人还是未来是机器,

790
0:42:08.000 --> 0:42:11.000
你说有没有概念上的传承,

791
0:42:11.000 --> 0:42:13.000
一定是有的。

792
0:42:17.000 --> 0:42:23.000
刚才其实也提到分布式训练模型切分并行计算的一些问题,

793
0:42:23.000 --> 0:42:24.000
这个问题上,

794
0:42:24.000 --> 0:42:30.000
龙老师具体在进行训练的时候有遇到过哪些卡点,

795
0:42:30.000 --> 0:42:33.000
然后有一些比较好的解决方法吗?

796
0:42:35.000 --> 0:42:37.000
这个其实是一个非常痛苦的事情,

797
0:42:37.000 --> 0:42:40.000
现在可能最好的并行计算方案,

798
0:42:40.000 --> 0:42:44.000
核心还是基于Megatron那套框架,

799
0:42:44.000 --> 0:42:50.000
但是研究员们更喜欢用Pytorch去反复调它这个模型架构,

800
0:42:50.000 --> 0:42:53.000
而把Pytorch在马甲移到Megatron上,

801
0:42:53.000 --> 0:42:56.000
其实是一个比较辛苦的一件事情,

802
0:42:56.000 --> 0:42:58.000
就导致出现出一个gap,

803
0:42:58.000 --> 0:43:00.000
做分析训练的人就说,

804
0:43:00.000 --> 0:43:01.000
你不要再调整结构,

805
0:43:01.000 --> 0:43:06.000
我们就用Megatron支持BERT-T5和GBT,

806
0:43:06.000 --> 0:43:08.000
改也小改别大改,

807
0:43:08.000 --> 0:43:10.000
因为整套代码都不一样,

808
0:43:10.000 --> 0:43:12.000
那研究员可能更心疼,

809
0:43:12.000 --> 0:43:15.000
我现在小调好将来大了也管用,

810
0:43:15.000 --> 0:43:17.000
但实际上现在这个假设是不成立的,

811
0:43:17.000 --> 0:43:21.000
就是涌现这件事情直接导致很多的算法实验,

812
0:43:21.000 --> 0:43:24.000
你在小规模上是做不出来的,

813
0:43:24.000 --> 0:43:25.000
或者是永远也看不到的,

814
0:43:25.000 --> 0:43:28.000
这件事就会导致大家很痛苦,

815
0:43:28.000 --> 0:43:31.000
那我们要么选择一个分布式架构,

816
0:43:31.000 --> 0:43:33.000
在上面去做模型实验,

817
0:43:33.000 --> 0:43:36.000
要不然你就放弃有限能力去做小规模实验,

818
0:43:36.000 --> 0:43:39.000
在去年可能这件事还说得通,

819
0:43:39.000 --> 0:43:41.000
但今年这件事已经说不通了。

820
0:43:42.000 --> 0:43:46.000
了解,除了Megatron之外,

821
0:43:46.000 --> 0:43:48.000
其实还会有像微软有DeepSpeed,

822
0:43:48.000 --> 0:43:52.000
或者像最近有一些很热的开源项目,

823
0:43:52.000 --> 0:43:56.000
像ProSum.AI,这些开源的方案能够帮助到我们

824
0:43:56.000 --> 0:44:00.000
去解决这些分布式并行训练的问题吗?

825
0:44:01.000 --> 0:44:04.000
可以,现在其实最收套的方案应该是用

826
0:44:04.000 --> 0:44:08.000
微软这边其实Fork可以把Megatron

827
0:44:08.000 --> 0:44:10.000
和DeepSpeed进行结合,

828
0:44:10.000 --> 0:44:12.000
所以那个项目叫Megatron DeepSpeed,

829
0:44:12.000 --> 0:44:14.000
那个是现在比较收套的方案,

830
0:44:14.000 --> 0:44:16.000
所以其实微软这边也在用这个方案,

831
0:44:16.000 --> 0:44:19.000
当年他们训练530B的模型的时候

832
0:44:19.000 --> 0:44:21.000
是用这套框架去训练的,

833
0:44:21.000 --> 0:44:23.000
所以现在有两家合作了。

834
0:44:24.000 --> 0:44:25.000
了解,了解。

835
0:44:25.000 --> 0:44:29.000
Colossal AI目前我们没有看到哪个开源项目

836
0:44:29.000 --> 0:44:31.000
把模型给训出来了。

837
0:44:32.000 --> 0:44:36.000
OK,除了像并行训练这里的诉求,

838
0:44:36.000 --> 0:44:38.000
作为一个Researcher,

839
0:44:38.000 --> 0:44:41.000
就是农老师假设今天要跟新蓝去做对接,

840
0:44:41.000 --> 0:44:45.000
会给新蓝提除了并行训练之外

841
0:44:45.000 --> 0:44:47.000
还有哪些方面的诉求呢?

842
0:44:47.000 --> 0:44:49.000
其实就刚才我说的移植的活,

843
0:44:49.000 --> 0:44:53.000
比如说Researcher可能我用PyTorch去验证

844
0:44:53.000 --> 0:44:55.000
比如说我各种模型结构上的一些细微调整,

845
0:44:55.000 --> 0:44:57.000
或者说比如Tokenizer的各种细节调整,

846
0:44:57.000 --> 0:45:01.000
那些调整其实都需要翻译到Megatron这套框架上,

847
0:45:01.000 --> 0:45:05.000
这个实际上是一个类似于研发的Pipeline吧。

848
0:45:08.000 --> 0:45:10.000
那对于新蓝老师来聊,

849
0:45:10.000 --> 0:45:13.000
就是说这一套的这些诉求,

850
0:45:13.000 --> 0:45:16.000
我可以做到一个很好的标准,

851
0:45:16.000 --> 0:45:24.000
还是我需要不停的堆这个人力和硬件工程师去服务上层的Researcher呢?

852
0:45:26.000 --> 0:45:29.000
就我觉得这个事儿可能得另外看,

853
0:45:29.000 --> 0:45:35.000
现在我看有很多的创业公司还有大公司都在说我们疯狂对人进,

854
0:45:35.000 --> 0:45:41.000
但是其实现在大模型训练这件事情并不是一个非常清晰的分工,

855
0:45:41.000 --> 0:45:47.000
就很难说我有几个算法的研究员或者我有几个工程人员,

856
0:45:47.000 --> 0:45:51.000
大家怎么一结合就这个事儿他做完交给他,

857
0:45:51.000 --> 0:45:55.000
他提需求他去做,他去怎么这么一步一步做出来,

858
0:45:55.000 --> 0:46:01.000
有限阶段更倾向于是说算法人员工程员大家坐在一块儿,

859
0:46:01.000 --> 0:46:03.000
彼此支持是交融的,

860
0:46:03.000 --> 0:46:09.000
算法和工程员一起去讨论说我们现在要做这个东西应该怎么去做,

861
0:46:09.000 --> 0:46:12.000
我们应该怎么去针对这个机器去调,

862
0:46:12.000 --> 0:46:14.000
举一个例子,

863
0:46:14.000 --> 0:46:16.000
就刚才龙老师提到Macro,

864
0:46:16.000 --> 0:46:22.000
那我们之前做GPTR的时候就是整个自己重新做了一套类似于Macro的东西,

865
0:46:22.000 --> 0:46:25.000
但是整个模型切分的那一部分的时候,

866
0:46:25.000 --> 0:46:29.000
那就得针对性的去看模型的这一部分,

867
0:46:29.000 --> 0:46:31.000
我现在有这样的显卡,

868
0:46:31.000 --> 0:46:33.000
这个显卡的计算能力是什么,

869
0:46:33.000 --> 0:46:34.000
它的通讯能力是什么,

870
0:46:34.000 --> 0:46:36.000
机器内的通讯能力是什么,

871
0:46:36.000 --> 0:46:37.000
机器间的通讯能力是什么,

872
0:46:37.000 --> 0:46:40.000
所以我们现在这部分应该这么这么切,

873
0:46:40.000 --> 0:46:42.000
模型的那部分应该这么切,

874
0:46:42.000 --> 0:46:45.000
然后就这些细节是都要大家联合的去对的,

875
0:46:45.000 --> 0:46:50.000
所以就它应该说是标准化的另外一个极端,

876
0:46:50.000 --> 0:46:54.000
就是就最好就恨不得就是一两个人,

877
0:46:54.000 --> 0:46:56.000
非常少量的人坐在一起,

878
0:46:56.000 --> 0:46:57.000
集中把它搞定,

879
0:46:57.000 --> 0:47:01.000
这是它现在为什么国内大家想要这么快复现都这么难的一个原因,

880
0:47:01.000 --> 0:47:03.000
它不是标准化的。

881
0:47:03.000 --> 0:47:05.000
了解了解,

882
0:47:05.000 --> 0:47:08.000
那听起来如果我们要去圈一个大模型,

883
0:47:08.000 --> 0:47:11.000
其实现阶段还是一个比较混沌的分工状态,

884
0:47:11.000 --> 0:47:15.000
这对整个项目管理和对于产品端的这个诉求,

885
0:47:15.000 --> 0:47:17.000
其实会要求很高,

886
0:47:17.000 --> 0:47:18.000
在这件事情上,

887
0:47:18.000 --> 0:47:23.000
关书会怎么去看整个大模型研发的这个过程管理,

888
0:47:23.000 --> 0:47:30.000
以及我们怎么去建立一些checkpoint去控制整个大模型研发中的风险呢?

889
0:47:30.000 --> 0:47:32.000
对,

890
0:47:32.000 --> 0:47:33.000
针对这个问题的话,

891
0:47:33.000 --> 0:47:36.000
其实目前国内来讲的话,

892
0:47:36.000 --> 0:47:39.000
大家可能都没有太多的一个经验,

893
0:47:39.000 --> 0:47:43.000
所以我们更多的是可以去参考OpenAI,

894
0:47:43.000 --> 0:47:49.000
来去看看它对外的这种信息里面会包含哪些工作模块,

895
0:47:49.000 --> 0:47:53.000
那就我们已经能看到的这种公开信息来去说的话,

896
0:47:53.000 --> 0:47:57.000
其实至少会包含三个大的方向,

897
0:47:57.000 --> 0:48:00.000
分别是数据的这个工作方向,

898
0:48:00.000 --> 0:48:04.000
以及算法,以及这个训练,

899
0:48:04.000 --> 0:48:05.000
也就是工程,

900
0:48:05.000 --> 0:48:06.000
这样三个方向,

901
0:48:06.000 --> 0:48:11.000
那其实每个方向里面我们去看到他们具体的这个工作,

902
0:48:11.000 --> 0:48:14.000
也能够再去拆分出一些更细的模块,

903
0:48:14.000 --> 0:48:17.000
比如说像数据这一块,

904
0:48:17.000 --> 0:48:25.000
其实就能够分为说面向预训练模型所使用的这个预训练的这样一个data,

905
0:48:25.000 --> 0:48:30.000
也包括说因为像Chad GPT,

906
0:48:30.000 --> 0:48:32.000
他有instruct tuning这样一个非常重要的环节,

907
0:48:32.000 --> 0:48:36.000
那instruct data也是一个很重要的模块,

908
0:48:36.000 --> 0:48:44.000
还有就是强化学习这一部分所使用的人工去排序和打分的这样一个数据,

909
0:48:44.000 --> 0:48:45.000
那所有的这些数据,

910
0:48:45.000 --> 0:48:52.000
它其实都是会有一个从搜集再去做治理,

911
0:48:52.000 --> 0:48:55.000
以及清洗这样一个系统的一个过程,

912
0:48:55.000 --> 0:48:56.000
那这是数据的部分,

913
0:48:56.000 --> 0:48:58.000
那像算法的部分呢,

914
0:48:58.000 --> 0:49:04.000
我相信即使是OpenAI他们内部也会对整个算法的选行,

915
0:49:04.000 --> 0:49:06.000
包括一些这个架构,

916
0:49:06.000 --> 0:49:08.000
以及像如何训练,

917
0:49:08.000 --> 0:49:11.000
有很多的技术方案的一些实验,

918
0:49:11.000 --> 0:49:15.000
最后才能确定如何去训出一个模型,

919
0:49:15.000 --> 0:49:17.000
那确定完算法之后,

920
0:49:17.000 --> 0:49:25.000
整个训练的这个环节因为需要用到上万级别的一个GPU来去做训练,

921
0:49:25.000 --> 0:49:30.000
那整个这件事情的如何更高效的去做分布式,

922
0:49:30.000 --> 0:49:34.000
如何去提升这个模型的训练的速度,

923
0:49:34.000 --> 0:49:37.000
以及中间刚才像欣然提到的,

924
0:49:37.000 --> 0:49:43.000
有很多就是复杂的这种系统的工作都是需要去完成的,

925
0:49:43.000 --> 0:49:45.000
所以整体来讲的话,

926
0:49:45.000 --> 0:49:47.000
我们通过这个OpenAI,

927
0:49:47.000 --> 0:49:49.000
它已经公开的信息,

928
0:49:49.000 --> 0:49:52.000
我们完全可以认为就是大模型的这个研发,

929
0:49:52.000 --> 0:49:54.000
它未必涉及到很多人,

930
0:49:54.000 --> 0:49:59.000
但是它一定是一个非常系统化的这样的一个工作。

931
0:50:03.000 --> 0:50:04.000
了解了解,

932
0:50:04.000 --> 0:50:06.000
贯爽刚才讲得非常详细啊,

933
0:50:06.000 --> 0:50:09.000
那其实有很多问题想展开,

934
0:50:09.000 --> 0:50:13.000
那我们就先从这个算法的这个刚才说的这个技术选行上去,

935
0:50:13.000 --> 0:50:15.000
这个先讨论哈,

936
0:50:15.000 --> 0:50:19.000
就是说刚才其实我们有提到我们整个算法,

937
0:50:19.000 --> 0:50:22.000
可能如果要去做一个类GDP产品的话,

938
0:50:22.000 --> 0:50:24.000
会有三个大的阶段,

939
0:50:24.000 --> 0:50:25.000
一个是预训练阶段,

940
0:50:25.000 --> 0:50:27.000
一个是instruction tuning的阶段,

941
0:50:27.000 --> 0:50:29.000
一个是IOHF的阶段,

942
0:50:29.000 --> 0:50:31.000
首先预训练模型,

943
0:50:31.000 --> 0:50:35.000
我们一定要这个从头,

944
0:50:35.000 --> 0:50:36.000
就预训练模型,

945
0:50:36.000 --> 0:50:43.000
我们现在会有哪些可选的一些开源方案去进行这个选择呢?

946
0:50:43.000 --> 0:50:44.000
这我想讲一下吧,

947
0:50:44.000 --> 0:50:47.000
就是其实现在经过这几年的这个发展,

948
0:50:47.000 --> 0:50:48.000
包括开源设计的发展,

949
0:50:48.000 --> 0:50:50.000
其实GDP的模型,

950
0:50:50.000 --> 0:50:54.000
其实大家可选的这个就3.0这个版本,

951
0:50:54.000 --> 0:50:55.000
可选的这个起点其实挺多的,

952
0:50:55.000 --> 0:50:57.000
就首先最早是GDP Neo,

953
0:50:57.000 --> 0:50:59.000
就不同尺寸,

954
0:50:59.000 --> 0:51:05.000
那其实从125Billion最大到这个GDPJ,

955
0:51:05.000 --> 0:51:06.000
那个是20Billion左右,

956
0:51:06.000 --> 0:51:08.000
其实都是可选的一个选项,

957
0:51:08.000 --> 0:51:10.000
这个范围的话,

958
0:51:10.000 --> 0:51:12.000
其实做各种各样的实验,

959
0:51:12.000 --> 0:51:15.000
去观察模型的效果都是比较方便的,

960
0:51:15.000 --> 0:51:17.000
然后它的这个,

961
0:51:17.000 --> 0:51:19.000
尤其它用的这个语调Pile的数据机,

962
0:51:19.000 --> 0:51:21.000
基本上也是被大家反复去验证过,

963
0:51:21.000 --> 0:51:23.000
一个比较好的一个数据机,

964
0:51:23.000 --> 0:51:25.000
然后另外就是说,

965
0:51:25.000 --> 0:51:27.000
如果我们要想到这个百Billion级别的话,

966
0:51:27.000 --> 0:51:28.000
可能现在只有两个,

967
0:51:28.000 --> 0:51:29.000
就是一个OPT,

968
0:51:29.000 --> 0:51:30.000
一个BLOOM,

969
0:51:30.000 --> 0:51:31.000
一个是纯英文的,

970
0:51:31.000 --> 0:51:32.000
一个多语言的,

971
0:51:32.000 --> 0:51:34.000
这两个模型的话,

972
0:51:34.000 --> 0:51:35.000
就是各有千秋吧,

973
0:51:35.000 --> 0:51:38.000
然后对两个模型的好坏的评价,

974
0:51:38.000 --> 0:51:40.000
其实也有一些争议,

975
0:51:40.000 --> 0:51:41.000
然后最近的话,

976
0:51:41.000 --> 0:51:43.000
就是Meta这个Lama这个模型,

977
0:51:43.000 --> 0:51:46.000
这个模型当然现在大家还没有很多的评估,

978
0:51:46.000 --> 0:51:49.000
但是也是一个比较有潜力的一个替代方案,

979
0:51:49.000 --> 0:51:52.000
它是支持20多种语言,

980
0:51:52.000 --> 0:51:54.000
不过好像都是拉丁语系的,

981
0:51:54.000 --> 0:51:56.000
了解,

982
0:51:56.000 --> 0:51:57.000
我这边稍微补充一下,

983
0:51:57.000 --> 0:51:59.000
就是刚才提到OPT和Lama,

984
0:51:59.000 --> 0:52:01.000
都是Meta发的这个模型,

985
0:52:01.000 --> 0:52:03.000
BLOOM是这个开源平台Hacking Face,

986
0:52:03.000 --> 0:52:06.000
大家共同训练的模型,

987
0:52:06.000 --> 0:52:07.000
OK,

988
0:52:07.000 --> 0:52:12.000
其实我个人会非常好奇这个RLHF的环节,

989
0:52:12.000 --> 0:52:16.000
因为其实我从不同的一些researcher口中,

990
0:52:16.000 --> 0:52:18.000
有听到一些不同的观点,

991
0:52:18.000 --> 0:52:23.000
有的人觉得RL其实是Chad GPT成功的一个非常关键的要素,

992
0:52:23.000 --> 0:52:26.000
但是有的researcher他给的观点是说,

993
0:52:26.000 --> 0:52:29.000
其实是不是使用了RL不重要,

994
0:52:29.000 --> 0:52:32.000
关键是有了human feedback,

995
0:52:32.000 --> 0:52:38.000
也就是说human feedback才是Chad GPT在alignment上做得非常好的一个关键原因,

996
0:52:38.000 --> 0:52:42.000
在这一点上想请问一下各位老师有什么自己的看法吗?

997
0:52:44.000 --> 0:52:46.000
要不我先说吧,

998
0:52:46.000 --> 0:52:51.000
因为我这边可能视角会不太一样,

999
0:52:51.000 --> 0:52:56.000
其实本身从算法上面来讲的话,

1000
0:52:56.000 --> 0:52:58.000
就是把强化学习,

1001
0:52:58.000 --> 0:53:01.000
然后接到一个语言模型,

1002
0:53:01.000 --> 0:53:07.000
然后去用强化学习的反馈去重新去调整语言模型参数,

1003
0:53:07.000 --> 0:53:13.000
这件事情并不是OpenAI的一个原创或者是独创,

1004
0:53:13.000 --> 0:53:17.000
因为其实我之前看到有20年的一篇论文,

1005
0:53:17.000 --> 0:53:21.000
他就用过和Instruct GPT完全一样的架构,

1006
0:53:21.000 --> 0:53:23.000
就是包括前面有Funtune,

1007
0:53:23.000 --> 0:53:28.000
然后最后会有强化学习这样一个模块,

1008
0:53:28.000 --> 0:53:31.000
就是三个部分组成的这样一个系统,

1009
0:53:31.000 --> 0:53:34.000
但是因为当时它是一个学校做的项目,

1010
0:53:34.000 --> 0:53:37.000
所以它的数据量也很小,

1011
0:53:37.000 --> 0:53:41.000
以及它只面向一个特定的应该是一个摘要这样一个任务来去做的,

1012
0:53:41.000 --> 0:53:44.000
所以本身从技术上面来讲的话,

1013
0:53:44.000 --> 0:53:47.000
这件事情确实不算是那么新,

1014
0:53:47.000 --> 0:53:51.000
所以从我的观点上面来去讲的话,

1015
0:53:51.000 --> 0:53:55.000
如果有了人工的这种反馈数据,

1016
0:53:55.000 --> 0:54:05.000
那这个反馈数据究竟是用强化学习来去reward model来去重新调整训练模型的参数呢?

1017
0:54:05.000 --> 0:54:09.000
还是说我有了这个human feedback之后,

1018
0:54:09.000 --> 0:54:14.000
我人也能去依据这些信息更好的去把强化学习做优化?

1019
0:54:14.000 --> 0:54:19.000
我觉得两者首先是肯定是都可以做的,

1020
0:54:19.000 --> 0:54:21.000
就是人也可以去做这个事情,

1021
0:54:21.000 --> 0:54:25.000
那人做了之后它会更好还是更坏?

1022
0:54:25.000 --> 0:54:28.000
这个其实是不确定的一点,

1023
0:54:28.000 --> 0:54:34.000
这个我觉得一会儿阿瑞桑娜老师也可以再去补充一下,

1024
0:54:34.000 --> 0:54:37.000
所以从我的这个产品的视角来去看的话,

1025
0:54:37.000 --> 0:54:48.000
我肯定认为就是Chad GPT它的这个成功更像是一个产品加入到算法之后的一个成功,

1026
0:54:48.000 --> 0:54:54.000
它把用户的这些反馈加入到整个产品优化这样一个系统里面,

1027
0:54:54.000 --> 0:54:59.000
其实它就会很像这种搜索点击率的这个准确性的一个提升,

1028
0:54:59.000 --> 0:55:01.000
包括像推荐准确的一个提升,

1029
0:55:01.000 --> 0:55:05.000
它都是因为把用户的行为给加入进来了,

1030
0:55:05.000 --> 0:55:08.000
所以它会越来越好,这是我的观点。

1031
0:55:10.000 --> 0:55:12.000
两位像吗?老师?

1032
0:55:12.000 --> 0:55:18.000
其实看Instract GPT这篇文本身做了一些实验吧,

1033
0:55:18.000 --> 0:55:22.000
其实里面Funtune这一步带来提升是比较明显的,

1034
0:55:22.000 --> 0:55:24.000
所以我才会有很多人想,

1035
0:55:24.000 --> 0:55:26.000
我是不是只做Funtune就可以,

1036
0:55:26.000 --> 0:55:28.000
或者已经达到八成的效果,

1037
0:55:28.000 --> 0:55:32.000
然后强化学习这部分的两成我是不是可以先不那么着急,

1038
0:55:32.000 --> 0:55:34.000
我觉得这是主要的一个争议点,

1039
0:55:34.000 --> 0:55:36.000
但实际上我们去想的话,

1040
0:55:36.000 --> 0:55:38.000
为什么强化学习这么重要?

1041
0:55:38.000 --> 0:55:45.000
无论是OpenAI在这最近差不多有十年的技术路线上强化学习扮演一个非常重要的角色,

1042
0:55:45.000 --> 0:55:48.000
然后还另外从数据标注角度来讲,

1043
0:55:48.000 --> 0:55:52.000
如果大家有兴趣的话可以去看一下Lion的OpenAssist这个项目,

1044
0:55:52.000 --> 0:55:54.000
大家都会去上面做标注,

1045
0:55:54.000 --> 0:55:58.000
你会发现去做人工标注会变得越来越难,

1046
0:55:58.000 --> 0:56:00.000
因为简单的标注大家都标完了,

1047
0:56:00.000 --> 0:56:02.000
后面的标注会变得很困难,

1048
0:56:02.000 --> 0:56:05.000
那什么简单呢?就是评价标注的好坏会变得很简单,

1049
0:56:05.000 --> 0:56:12.000
也就是说现在模型拿到Fenton的数据可能已经达到了平均标注源的水准了,

1050
0:56:12.000 --> 0:56:15.000
但你想让它去更进一步变得更好的时候,

1051
0:56:15.000 --> 0:56:22.000
那可能去强化它或者说去优化它这个评价模型会来的更简单一些,

1052
0:56:22.000 --> 0:56:28.000
所以说达到八成效果就是人工标注然后纯做Fenton,

1053
0:56:28.000 --> 0:56:31.000
那你想走得更远的话那只能靠下方学习,

1054
0:56:31.000 --> 0:56:33.000
这是我的观点。

1055
0:56:33.000 --> 0:56:38.000
那老师能不能给我这个不太懂这块的科普一下,

1056
0:56:38.000 --> 0:56:44.000
就是整个强化学习的时候它学习的loss大概是怎么设的,

1057
0:56:44.000 --> 0:56:49.000
就是简单科普就OK了,

1058
0:56:49.000 --> 0:56:54.000
然后以及后面的Fenton的话提供的数据是什么样的信息呢?

1059
0:56:54.000 --> 0:56:58.000
就总不能它的整个强化学习的过程是说模型出一个,

1060
0:56:58.000 --> 0:57:01.000
然后我立刻标,标完再告诉它吧。

1061
0:57:01.000 --> 0:57:07.000
我稍微讲一下,它是分两步的,第一步先Fenton,

1062
0:57:07.000 --> 0:57:11.000
就是你做强化学习之前是必做Fenton的,

1063
0:57:11.000 --> 0:57:15.000
这个我猜是他们有些做过一些实验,

1064
0:57:15.000 --> 0:57:18.000
比如说不Fenton强化学习效果不明显之类的,

1065
0:57:18.000 --> 0:57:24.000
那Fenton之后加了强化学习我们可以类比一个经验,

1066
0:57:24.000 --> 0:57:26.000
可以去打游戏,

1067
0:57:26.000 --> 0:57:29.000
那我可能模型在我这个环境里面根据一些问题,

1068
0:57:29.000 --> 0:57:31.000
然后我输出很多很多结果,

1069
0:57:31.000 --> 0:57:34.000
然后另外一个模型主要负责来判别,

1070
0:57:34.000 --> 0:57:36.000
这个给你打个分,

1071
0:57:36.000 --> 0:57:39.000
你这个是一个好的回答还是一个不好的回答,

1072
0:57:39.000 --> 0:57:45.000
那这个判别的模型可能是来自于之前的一个标注的结果,

1073
0:57:45.000 --> 0:57:48.000
就比如说我会标三个回答,

1074
0:57:48.000 --> 0:57:50.000
那这三个回答我会有排序,

1075
0:57:50.000 --> 0:57:52.000
那高的我就认为是一个好的回答,

1076
0:57:52.000 --> 0:57:54.000
那低的我就会认为是一个差的回答,

1077
0:57:54.000 --> 0:57:56.000
这样我们就可以训练出一个模型来判断,

1078
0:57:56.000 --> 0:57:58.000
这个回答到底是好是坏,

1079
0:57:58.000 --> 0:58:01.000
这个就像下回棋输和赢一样,

1080
0:58:01.000 --> 0:58:03.000
会打游戏你的角色一波死掉一样,

1081
0:58:03.000 --> 0:58:06.000
又会给这个Logic Model一个反馈,

1082
0:58:06.000 --> 0:58:08.000
就是说你这个输出是好是坏,

1083
0:58:08.000 --> 0:58:12.000
然后通过这个信号再反复去调整这个模型的权重。

1084
0:58:14.000 --> 0:58:19.000
OK,所以其实并不是真的有人立刻实时的去给

1085
0:58:19.000 --> 0:58:22.000
这个生成出来的结果去评分是吧,

1086
0:58:22.000 --> 0:58:27.000
而是说先通过人工标注出的一个判别模型,

1087
0:58:27.000 --> 0:58:32.000
然后再用判别模型去训这个强化学级前面的大模型,

1088
0:58:32.000 --> 0:58:34.000
是这样的。

1089
0:58:34.000 --> 0:58:35.000
对的。

1090
0:58:35.000 --> 0:58:37.000
有一种那个干的感觉,

1091
0:58:37.000 --> 0:58:40.000
就是先学个判别器出来。

1092
0:58:40.000 --> 0:58:44.000
对,因为之前的难点在于之前的判别器

1093
0:58:44.000 --> 0:58:48.000
大家都用规则,就围棋输了是一个可以用规则写出来的,

1094
0:58:48.000 --> 0:58:51.000
但是现在这个模型的好坏其实很难用规则去写,

1095
0:58:51.000 --> 0:58:53.000
这个时候必须加一个模型,

1096
0:58:53.000 --> 0:58:55.000
而且OpenAI这个模型其实挺大的,

1097
0:58:55.000 --> 0:58:58.000
它是用一个6B的模型去做这个判别,

1098
0:58:58.000 --> 0:59:01.000
我猜是因为过小的模型根本就判断不出来质量好坏。

1099
0:59:03.000 --> 0:59:07.000
明白了,那我想象的那种就是机器奴役人类,

1100
0:59:07.000 --> 0:59:09.000
机器不断的问这个好不好快说,

1101
0:59:09.000 --> 0:59:11.000
这个场景没有出现。

1102
0:59:13.000 --> 0:59:16.000
如果你人足够多的话,我怀疑这个效果更好。

1103
0:59:18.000 --> 0:59:22.000
对,这里刚才其实提到就是这个龙老师提到一点,

1104
0:59:22.000 --> 0:59:25.000
就是说因为这个人工标数据会越来越难,

1105
0:59:25.000 --> 0:59:32.000
或者说是人工标的这个结果已经逐渐和模型能够生产出来的,

1106
0:59:32.000 --> 0:59:35.000
或者说是生产出来这个数据差不多了,

1107
0:59:35.000 --> 0:59:38.000
那就是我想再追问一下,

1108
0:59:38.000 --> 0:59:41.000
就是那为什么加入了强化学习之后,

1109
0:59:41.000 --> 0:59:44.000
它能够去解决这个问题呢?

1110
0:59:44.000 --> 0:59:47.000
或者说为什么加入强化学习之后,

1111
0:59:47.000 --> 0:59:55.000
它是怎么样让人工标准数据没有非常大提升的情况下,

1112
0:59:55.000 --> 1:00:00.000
它让这个模型的这个效果会有提升呢?

1113
1:00:03.000 --> 1:00:05.000
我这里面有一个猜测,

1114
1:00:05.000 --> 1:00:08.000
就是说大家去玩猜GPT的时候,

1115
1:00:08.000 --> 1:00:10.000
观察到一个现象,

1116
1:00:10.000 --> 1:00:14.000
就是说这个模型会给你一些看上去很对,

1117
1:00:14.000 --> 1:00:17.000
但实际上有事实错误的答案,

1118
1:00:17.000 --> 1:00:19.000
这个我猜大家都会碰到。

1119
1:00:19.000 --> 1:00:23.000
我猜这个可能原因就是说我们这个reward model和这个判别模型,

1120
1:00:23.000 --> 1:00:27.000
是很容易去从句子结构或者语法结构上,

1121
1:00:27.000 --> 1:00:30.000
以及整个输出形式上来判断它是不是好坏的,

1122
1:00:30.000 --> 1:00:33.000
然后但是涉及到知识性的东西的时候,

1123
1:00:33.000 --> 1:00:35.000
这件事会变得越来越难,

1124
1:00:35.000 --> 1:00:38.000
所以刚才我说走得更远是因为标注成本很高,

1125
1:00:38.000 --> 1:00:40.000
那它可以标注更多样的数据,

1126
1:00:40.000 --> 1:00:42.000
但是想完全超过人类,

1127
1:00:42.000 --> 1:00:44.000
这个事还是有一定难度的,

1128
1:00:44.000 --> 1:00:46.000
所以这其实是一个比较小的改进,

1129
1:00:46.000 --> 1:00:48.000
所以我说这个两成和八成的区别。

1130
1:00:50.000 --> 1:00:52.000
嗯,明白,

1131
1:00:52.000 --> 1:00:57.000
那这里我觉得又有一个挺有意思的畅想,

1132
1:00:57.000 --> 1:01:04.000
就是说因为目前OpenAI它的模型的算法效果很好,

1133
1:01:04.000 --> 1:01:07.000
就是它生成出来的内容质量很高,

1134
1:01:07.000 --> 1:01:13.000
那对于一些现在模型生成效果还不够好的,

1135
1:01:13.000 --> 1:01:16.000
这样的一些组织,

1136
1:01:16.000 --> 1:01:18.000
他们在去做模型的时候,

1137
1:01:18.000 --> 1:01:23.000
我们可以认为他们是直接可以使用OpenAI它的模型,

1138
1:01:23.000 --> 1:01:26.000
直接生成出来的效果去作为数据的吗?

1139
1:01:28.000 --> 1:01:32.000
其实如果大家去看各种各样的这种LP的公众号的话,

1140
1:01:32.000 --> 1:01:35.000
其实在下面讨论区已经有很多人提到这种想法,

1141
1:01:35.000 --> 1:01:37.000
就是OpenAI in the loop,

1142
1:01:37.000 --> 1:01:39.000
这已经是一个公开的想法,

1143
1:01:39.000 --> 1:01:41.000
并不是说少数人的想法。

1144
1:01:43.000 --> 1:01:48.000
OK,那这里面我再往前去这个瞎想一步,

1145
1:01:48.000 --> 1:01:54.000
就是说因为我们知道这个生成模型它其实是有随机性的,

1146
1:01:54.000 --> 1:01:57.000
就是虽然人教他的是这些内容,

1147
1:01:57.000 --> 1:01:59.000
但是它生成的时候一定还是会有一些随机性,

1148
1:01:59.000 --> 1:02:02.000
出现意外之外的这种生成内容,

1149
1:02:02.000 --> 1:02:08.000
那我们举个例子,比如说人现在的标注数据达到了80分,

1150
1:02:08.000 --> 1:02:12.000
那这个所以模型它的这个效果,

1151
1:02:12.000 --> 1:02:15.000
它的期望值可能也是80分,

1152
1:02:15.000 --> 1:02:18.000
但是它可能会随着这个80分上下去做波动,

1153
1:02:18.000 --> 1:02:20.000
有的时候可能会出来一些效果更差的,

1154
1:02:20.000 --> 1:02:23.000
有的时候可能会出一些效果更好的,

1155
1:02:23.000 --> 1:02:25.000
那如果我有一种方法,

1156
1:02:25.000 --> 1:02:29.000
就是把它生成出来的这种效果更好的,

1157
1:02:29.000 --> 1:02:33.000
超过人工的这种数据给筛出来,

1158
1:02:33.000 --> 1:02:38.000
那是不是意味着我拥有了一种自动生产标注数据的方法?

1159
1:02:41.000 --> 1:02:43.000
你这个想法倒挺好,

1160
1:02:43.000 --> 1:02:45.000
其实我没有从这个角度想过,

1161
1:02:45.000 --> 1:02:48.000
这是来自产品经理的视角,

1162
1:02:48.000 --> 1:02:50.000
也许是行得通的,

1163
1:02:50.000 --> 1:02:53.000
但是其实我想说这个东西是不是,

1164
1:02:53.000 --> 1:02:55.000
保险打断了,

1165
1:02:55.000 --> 1:03:00.000
其实我想说这个东西是不是就是XRPPC本身自己的网页做出来的一个初衷,

1166
1:03:00.000 --> 1:03:03.000
因为在那个网页上你可以直接给它点赞,

1167
1:03:05.000 --> 1:03:06.000
我觉得是的,

1168
1:03:06.000 --> 1:03:09.000
我就是看到了它的这个标注的行为,

1169
1:03:09.000 --> 1:03:13.000
所以我产生了这个想法,

1170
1:03:15.000 --> 1:03:16.000
我这么想,

1171
1:03:16.000 --> 1:03:18.000
首先那个点赞按钮我几乎没用过,

1172
1:03:18.000 --> 1:03:20.000
我好像就用过一次看看交互是什么样,

1173
1:03:20.000 --> 1:03:22.000
然后就没再用过了,

1174
1:03:22.000 --> 1:03:26.000
然后另外的话其实你去看OpenAI去年八月份发了一篇博客,

1175
1:03:26.000 --> 1:03:33.000
那他们其实就是说点赞还是收集数据这件事对他们来说可能只是跟微软合作的一部分,

1176
1:03:33.000 --> 1:03:36.000
并不是他们这个roadmap上一个很重要的一个环,

1177
1:03:36.000 --> 1:03:41.000
他们那篇文章去讲他们后面一步就是我们达到HUMAN LINEWORK之后怎么办,

1178
1:03:41.000 --> 1:03:46.000
因为我们已经没有足够的聪明的人去评判模型输出的好坏了,

1179
1:03:46.000 --> 1:03:52.000
那他们的下一步计划是说怎么让模型去产生research的计划,

1180
1:03:52.000 --> 1:03:55.000
然后人去评判research计划的好坏,

1181
1:03:55.000 --> 1:03:57.000
那这一步我觉得是他们想做的事情,

1182
1:03:57.000 --> 1:04:00.000
而不是简单说我模型优化了两个点,

1183
1:04:00.000 --> 1:04:03.000
我觉得OpenAI更关心的是这种代词的变化,

1184
1:04:03.000 --> 1:04:06.000
如果模型能够辅助去做research的话,

1185
1:04:06.000 --> 1:04:09.000
这个产生的这种代词的变化才会更明显。

1186
1:04:09.000 --> 1:04:12.000
这个其实挺抽象,

1187
1:04:12.000 --> 1:04:13.000
因为那篇文章我也看了,

1188
1:04:13.000 --> 1:04:19.000
它的第二步其实是说先用model去取代human去给出feedback,

1189
1:04:19.000 --> 1:04:23.000
这也是像Anthropic他们听说在用的这个方法,

1190
1:04:23.000 --> 1:04:28.000
那什么叫做用模型自己去产生research的计划,

1191
1:04:28.000 --> 1:04:35.000
就这个以我有限的想象力好像没有办法很好的去理解这个抽象的概念。

1192
1:04:37.000 --> 1:04:40.000
我回答不了这个问题,对我来说也很抽象。

1193
1:04:40.000 --> 1:04:42.000
好的好的,行。

1194
1:04:42.000 --> 1:04:51.000
我觉得这个问题可能可以从这种基本的逻辑去做推演,

1195
1:04:51.000 --> 1:04:55.000
当然这个问题可能就会变得有点哲学,

1196
1:04:55.000 --> 1:04:56.000
就是什么意思呢?

1197
1:04:56.000 --> 1:05:02.000
就是说比如我们看到的文本类的这种信息小说或者是文章,

1198
1:05:02.000 --> 1:05:05.000
包括我们看到的这种图像,

1199
1:05:05.000 --> 1:05:09.000
其实它都是以一个一个文字的单元,

1200
1:05:09.000 --> 1:05:12.000
就是像素点的单元组合起来的,

1201
1:05:12.000 --> 1:05:15.000
那它既然是一种组合,

1202
1:05:15.000 --> 1:05:17.000
那现在算法它去做生成的时候,

1203
1:05:17.000 --> 1:05:22.000
不管是diffusion的模型还是语言模型,

1204
1:05:22.000 --> 1:05:28.000
他们其实也是在试图去做这种排列组合,

1205
1:05:28.000 --> 1:05:30.000
那只是说这些排列组合中,

1206
1:05:30.000 --> 1:05:36.000
它尽可能的会去模拟现在我们人类已经有的这些信息,

1207
1:05:36.000 --> 1:05:40.000
但是其实刚才提到的生成模型它是会有随机性的,

1208
1:05:40.000 --> 1:05:45.000
所以有可能它能生成出来的内容是预期之外的,

1209
1:05:45.000 --> 1:05:49.000
当然大多数时候它生成出来的是不好的,

1210
1:05:49.000 --> 1:05:52.000
但是保不齐就像玩游戏抽卡,

1211
1:05:52.000 --> 1:05:58.000
一下就抽出一个SSR,金色传说的这种感觉,

1212
1:05:58.000 --> 1:06:08.000
所以我觉得从某种角度上来讲它会有点像生物的遗传或者是变异,

1213
1:06:08.000 --> 1:06:11.000
就是它会往不同的方向去变异,

1214
1:06:11.000 --> 1:06:18.000
那如果说我们能够有一种方法去把它的好的变异有效地收集起来,

1215
1:06:18.000 --> 1:06:21.000
并且把它去重新利用到这个模型里面,

1216
1:06:21.000 --> 1:06:28.000
可能是不是就能够实现这个模型它就自我迭代了,

1217
1:06:28.000 --> 1:06:31.000
当然这个讨论好像又更抽象了一些。

1218
1:06:31.000 --> 1:06:34.000
我先说一个想象吧,

1219
1:06:34.000 --> 1:06:37.000
我觉得也是无责任胡说八道,

1220
1:06:37.000 --> 1:06:38.000
现在有一种感觉,

1221
1:06:38.000 --> 1:06:45.000
刚才冷老师说的这个盘编模型就好像是小学的考试,

1222
1:06:45.000 --> 1:06:47.000
然后中考高考这种标准的出题,

1223
1:06:47.000 --> 1:06:49.000
出个题你把这个题答对了,

1224
1:06:49.000 --> 1:06:54.000
然后等后边的这个比如出科研计划就很有可能是说,

1225
1:06:54.000 --> 1:06:56.000
你这些题都已经该做的都会做了,

1226
1:06:56.000 --> 1:06:58.000
这些题对于你来说都太easy了,

1227
1:06:58.000 --> 1:07:04.000
那么现在要考察你有没有这种独立思考的能力等等的时候,

1228
1:07:04.000 --> 1:07:06.000
这个时候你要自己写一篇博士论文,

1229
1:07:06.000 --> 1:07:09.000
然后这个论文要被顶会peer review过了,

1230
1:07:09.000 --> 1:07:12.000
才证明你是一个脑子清醒的博士,

1231
1:07:12.000 --> 1:07:17.000
我感觉以后这个训练过程可以参考一下现在的教育体系。

1232
1:07:17.000 --> 1:07:22.000
OK,我刚刚其实想了一个方案,

1233
1:07:22.000 --> 1:07:25.000
然后那个信源这个方案我也想到,

1234
1:07:25.000 --> 1:07:27.000
也想融进来,

1235
1:07:27.000 --> 1:07:29.000
就融合一下大家想法的话,

1236
1:07:29.000 --> 1:07:32.000
我猜一个就是说如果由我去做的话,

1237
1:07:32.000 --> 1:07:33.000
我会怎么做,

1238
1:07:33.000 --> 1:07:38.000
就我可能没有openai这些全球最聪明人这么聪明,

1239
1:07:38.000 --> 1:07:41.000
我的一个想法是在大概两年前,

1240
1:07:41.000 --> 1:07:42.000
我用copilot的时候,

1241
1:07:42.000 --> 1:07:44.000
我当时感觉这个东西非常有用,

1242
1:07:44.000 --> 1:07:47.000
而且我看到有一个博客去讨论说,

1243
1:07:47.000 --> 1:07:51.000
copilot这个工具为什么对openai这么重要,

1244
1:07:51.000 --> 1:07:55.000
因为这个工具能让openai的工程师能写出更好的代码,

1245
1:07:55.000 --> 1:07:57.000
来做出更好的模型,

1246
1:07:57.000 --> 1:08:02.000
那如果在research上有这么一个工具去辅助去写,

1247
1:08:02.000 --> 1:08:07.000
比如说研发方案或者说研究计划的话,

1248
1:08:07.000 --> 1:08:11.000
那它会不会做得比单纯人去做更好,

1249
1:08:11.000 --> 1:08:13.000
当然现在copilot其实有很多缺陷了,

1250
1:08:13.000 --> 1:08:15.000
比如说能看到的context过短,

1251
1:08:15.000 --> 1:08:19.000
以及能同时看到的文件数量不够多,

1252
1:08:19.000 --> 1:08:21.000
比如说我不能看到整个新的free mock的代码,

1253
1:08:21.000 --> 1:08:25.000
如果这些问题逐步被解决掉的话,

1254
1:08:25.000 --> 1:08:27.000
那是不是说有一个非常强的,

1255
1:08:27.000 --> 1:08:29.000
先是辅助人类写论文,

1256
1:08:29.000 --> 1:08:32.000
然后后来是完全代替人类写论文,

1257
1:08:32.000 --> 1:08:34.000
然后按照先前刚刚说的,

1258
1:08:34.000 --> 1:08:37.000
我把这些写论文撒到各个会议上,

1259
1:08:37.000 --> 1:08:39.000
然后好像是人类写的,

1260
1:08:39.000 --> 1:08:43.000
如果大量会议的人没有结果再给反馈的话,

1261
1:08:43.000 --> 1:08:45.000
是不是这条路就能行得通了?

1262
1:08:45.000 --> 1:08:50.000
我觉得我们在写论文这件事情上好像走得有点远,

1263
1:08:50.000 --> 1:08:55.000
要不我们拉回来继续讨论这个大模型吧。

1264
1:08:55.000 --> 1:09:00.000
好的好的,确实可能强化学给了我们太多的想象空间,

1265
1:09:00.000 --> 1:09:04.000
之后我们可以到时候再单开一期去讨论这方面,

1266
1:09:04.000 --> 1:09:10.000
其实回到现阶段来说,第一阶段我们要做一个HRT的产品的时候,

1267
1:09:10.000 --> 1:09:13.000
其实我有听很多的researcher有反馈,

1268
1:09:13.000 --> 1:09:16.000
强化学习的这个环节很容易不收敛,

1269
1:09:16.000 --> 1:09:23.000
除了在我们提高标注的质量的方式上去,

1270
1:09:23.000 --> 1:09:27.000
让我们rewarding的函数尽可能的优质,

1271
1:09:27.000 --> 1:09:34.000
还有一些什么样的trick可以让我们在这个环节打到一个比较好的效果?

1272
1:09:39.000 --> 1:09:41.000
这个问题其实很难回答,

1273
1:09:41.000 --> 1:09:44.000
首先我对强化学习的理解是没有那么深的,

1274
1:09:44.000 --> 1:09:46.000
因为不是长期扑在这个方向上,

1275
1:09:46.000 --> 1:09:52.000
而OpenAI负责这篇工作的作者,

1276
1:09:52.000 --> 1:09:55.000
我记得就是做PPO的作者,

1277
1:09:55.000 --> 1:09:59.000
在这方面可能会有一些insight是完全跟不上的,

1278
1:09:59.000 --> 1:10:01.000
这导致很难,

1279
1:10:01.000 --> 1:10:05.000
我的一个猜想是,

1280
1:10:05.000 --> 1:10:09.000
通过打游戏的这些强化学习算法里面看到不收敛,

1281
1:10:09.000 --> 1:10:12.000
往往是因为reward设计不够合理,

1282
1:10:12.000 --> 1:10:14.000
或者不够具有犯法性,

1283
1:10:14.000 --> 1:10:18.000
导致模型发现整个environment设置的一些bug,

1284
1:10:18.000 --> 1:10:21.000
然后利用这些bug去获得很高的reward,

1285
1:10:21.000 --> 1:10:25.000
然后在longer model这块的话,

1286
1:10:25.000 --> 1:10:27.000
想到犯法性,

1287
1:10:27.000 --> 1:10:31.000
我们第一想到增加模型的参数量,

1288
1:10:31.000 --> 1:10:33.000
因为我们看到GBT3参数量越大,

1289
1:10:33.000 --> 1:10:35.000
犯法性越好,

1290
1:10:35.000 --> 1:10:38.000
所以很有可能未来我们在reward这块的设置,

1291
1:10:38.000 --> 1:10:40.000
可能会参数量变得越来越大,

1292
1:10:40.000 --> 1:10:42.000
来提高它的犯法性,

1293
1:10:42.000 --> 1:10:44.000
来避免收敛不好的情况,

1294
1:10:44.000 --> 1:10:46.000
当然这个方面实验我也没有做过,

1295
1:10:46.000 --> 1:10:48.000
只是一个不负责任的猜想。

1296
1:10:48.000 --> 1:10:49.000
了解,

1297
1:10:49.000 --> 1:10:53.000
如果我们需要reward的犯法性更好的话,

1298
1:10:53.000 --> 1:10:57.000
其实也会要求我们有足够多的一些property,

1299
1:10:57.000 --> 1:10:59.000
或者足够多样的property数据,

1300
1:10:59.000 --> 1:11:05.000
这一点上似乎因为从GBT1 2018年发出来到今天,

1301
1:11:05.000 --> 1:11:10.000
OpenAI已经有非常多的一些类似像Playground之类的产品,

1302
1:11:10.000 --> 1:11:12.000
去收集各种各样的property,

1303
1:11:12.000 --> 1:11:14.000
在这一点上,

1304
1:11:14.000 --> 1:11:17.000
如果是一个新团队或者一个创业公司来说的话,

1305
1:11:17.000 --> 1:11:22.000
它怎么样在短期内可以得到更多的这些property数据呢?

1306
1:11:26.000 --> 1:11:28.000
这个可能怪说来答案更合适吧,

1307
1:11:28.000 --> 1:11:30.000
我觉得像是个产品问题。

1308
1:11:32.000 --> 1:11:33.000
OK,

1309
1:11:33.000 --> 1:11:37.000
我其实能够想到最好的方法,

1310
1:11:37.000 --> 1:11:40.000
可能是用ChadGBT的接口,

1311
1:11:40.000 --> 1:11:43.000
或者是OpenAI的达芬奇接口来去做生产,

1312
1:11:43.000 --> 1:11:48.000
因为这件事情刚才我们已经提到了,

1313
1:11:48.000 --> 1:11:54.000
OpenAI它做这件事情的最大的优势是在于,

1314
1:11:54.000 --> 1:12:00.000
它自从把这个GB3相关的这些算法做成API之后,

1315
1:12:00.000 --> 1:12:06.000
其实所有用户的这种使用的这种行为,

1316
1:12:06.000 --> 1:12:10.000
对他们来讲其实都是可以获取到的,

1317
1:12:10.000 --> 1:12:13.000
这一点来讲的话,

1318
1:12:13.000 --> 1:12:19.000
它其实是建立了一种非常强的产品的自增长的一个闭环,

1319
1:12:19.000 --> 1:12:24.000
就是说我有接口来去搜集到用户的数据,

1320
1:12:24.000 --> 1:12:31.000
并且我能够把这些数据很好的在体现到算法的效果的提升上面,

1321
1:12:31.000 --> 1:12:32.000
那以此呢,

1322
1:12:32.000 --> 1:12:34.000
我有了更好的算法效果,

1323
1:12:34.000 --> 1:12:37.000
就会有更多的人来去用我的这个接口,

1324
1:12:37.000 --> 1:12:40.000
那从而我就会有更多的这个数据,

1325
1:12:40.000 --> 1:12:45.000
所以它其实是一个所谓的这种业务的飞轮,

1326
1:12:45.000 --> 1:12:47.000
那这种业务飞轮转起来的话,

1327
1:12:47.000 --> 1:12:50.000
对于后发者再去进来的话,

1328
1:12:50.000 --> 1:12:58.000
那无非就是你要么真的是投足够多的资源去补这个差距,

1329
1:12:58.000 --> 1:13:03.000
那要么就是我觉得可能就是有一些这种很tricky的做法,

1330
1:13:03.000 --> 1:13:06.000
就比如刚才提到的OpenAI in the loop,

1331
1:13:06.000 --> 1:13:08.000
对吧,ChatGPT in the loop,

1332
1:13:08.000 --> 1:13:12.000
我觉得可能是一些比较取巧的这种做法。

1333
1:13:12.000 --> 1:13:14.000
了解,了解,

1334
1:13:14.000 --> 1:13:17.000
其实刚才冠叔也有提到,

1335
1:13:17.000 --> 1:13:22.000
就是说我们会发现OpenAI的go to market或者产品团队,

1336
1:13:22.000 --> 1:13:30.000
它其实在OpenAI的整个技术的前进过程当中起了非常大的一些作用,

1337
1:13:30.000 --> 1:13:32.000
那这里我也挺好奇,

1338
1:13:32.000 --> 1:13:35.000
作为一个大模型相关的这个产品方,

1339
1:13:35.000 --> 1:13:40.000
是不是说这一家公司其实未来如果需要在底层模型上

1340
1:13:40.000 --> 1:13:43.000
能够去保持一个相当的竞争力,

1341
1:13:43.000 --> 1:13:48.000
上层必须要有一些能够形成自己飞轮的一些应用,

1342
1:13:48.000 --> 1:13:52.000
而导致了它必须要去做应用层的事情呢?

1343
1:13:54.000 --> 1:13:57.000
这个我先来说吧,

1344
1:13:57.000 --> 1:14:00.000
我觉得还是从产品的视角来去看的话,

1345
1:14:00.000 --> 1:14:07.000
我会认为像就是instruct GBT包括chat GBT,

1346
1:14:07.000 --> 1:14:12.000
他们在技术和业务上面的成功,

1347
1:14:12.000 --> 1:14:15.000
其实更多的就是你刚才提到的,

1348
1:14:15.000 --> 1:14:24.000
就是把用户把应用层面的一些信息加到算法优化的一个结果,

1349
1:14:24.000 --> 1:14:27.000
尤其是chat GBT这件事情,

1350
1:14:27.000 --> 1:14:33.000
因为我们也会看到chat GBT它的迭代的速度其实也是非常快的,

1351
1:14:33.000 --> 1:14:39.000
这里面起到非常大的作用的其实就是刚才提到的,

1352
1:14:39.000 --> 1:14:42.000
就是大家去跟他对话,

1353
1:14:42.000 --> 1:14:46.000
甚至是会对他的对话内容来去做评价,

1354
1:14:46.000 --> 1:14:52.000
这会极大的提升它的算法层面的一个优势,

1355
1:14:52.000 --> 1:14:55.000
所以回到刚才的这个问题,

1356
1:14:55.000 --> 1:14:59.000
我会倾向于认为说大模型这件事情,

1357
1:14:59.000 --> 1:15:07.000
它已经脱离了单纯的科研来去做算法的这种创新,

1358
1:15:07.000 --> 1:15:15.000
或者说是去做一些网络结构上面的这样的研究的这样的一个工作,

1359
1:15:15.000 --> 1:15:19.000
而说他从instruct GBT出来的时候,

1360
1:15:19.000 --> 1:15:26.000
就已经意味着他开始把用户的反馈加入到了整个模型的迭代过程,

1361
1:15:26.000 --> 1:15:28.000
它已经变成一个产品了,

1362
1:15:28.000 --> 1:15:31.000
所以从这个角度来去看的话,

1363
1:15:31.000 --> 1:15:41.000
未来如果想要在这种同类的算法的方式之下去保持自己大模型效果的一个竞争力,

1364
1:15:41.000 --> 1:15:48.000
那是一定需要把用户的数据或者是业务场景的数据不断的去加进来,

1365
1:15:48.000 --> 1:15:50.000
了解了解,

1366
1:15:50.000 --> 1:15:56.000
所以其实我们需要把model training当成一个product来去进行这个规划,

1367
1:15:56.000 --> 1:15:59.000
但当然短期内可能我们要做一个迁移模型,

1368
1:15:59.000 --> 1:16:00.000
它相对比较简单,

1369
1:16:00.000 --> 1:16:05.000
但长期要有竞争力确实还是一件值得每个团队去思考的一件事情,

1370
1:16:05.000 --> 1:16:12.000
刚才其实有提到copilot对于openAI是一件非常有价值的事情,

1371
1:16:12.000 --> 1:16:17.000
其实我们会发现GBT3.5和ChartGBT在推理能力和COT上,

1372
1:16:17.000 --> 1:16:21.000
其实展现出了非常好的一个潜力,

1373
1:16:21.000 --> 1:16:30.000
具体很多人猜测代码训练可能是GBT系列的推理能力的一个很大的来源,

1374
1:16:30.000 --> 1:16:35.000
这个我们有在实际的过程当中去试验过,

1375
1:16:35.000 --> 1:16:39.000
就是代码训练给推理能力的加成到底有多少吗?

1376
1:16:39.000 --> 1:16:44.000
这个其实我还没有看到相关很solid的研究,

1377
1:16:44.000 --> 1:16:46.000
可能也许我有遗漏,

1378
1:16:46.000 --> 1:16:48.000
但是目前我还没有看到,

1379
1:16:48.000 --> 1:16:54.000
因为目前看到的无论是openAI还是已有的这些开源模型,

1380
1:16:54.000 --> 1:16:56.000
默认都是带代码数据的,

1381
1:16:56.000 --> 1:16:59.000
所以这个相容实验想做的话其实成本挺高的。

1382
1:17:02.000 --> 1:17:04.000
了解了,了解了,

1383
1:17:04.000 --> 1:17:10.000
OK,那今天假设我们在国内要去做一个千亿量级的大模型,

1384
1:17:10.000 --> 1:17:15.000
其实很多人会提到说中文数据的质量会不如英文数据高,

1385
1:17:15.000 --> 1:17:21.000
而且有的人给的这个可用数据的这个就预值,

1386
1:17:21.000 --> 1:17:24.000
质量预值在这个预值之上的这个数据,

1387
1:17:24.000 --> 1:17:28.000
他们认为可用数据可能中文只有英文的10%,

1388
1:17:28.000 --> 1:17:32.000
这个数据符合代码训练的这个要求,

1389
1:17:32.000 --> 1:17:35.000
这个数据符合大家的认知吗?

1390
1:17:35.000 --> 1:17:39.000
以及当这个中文数据质量不高的时候,

1391
1:17:39.000 --> 1:17:44.000
会影响我们去做这个中文的大源模型的训练吗?

1392
1:17:47.000 --> 1:17:50.000
这个我们其实就是比如说我们拿一个Pile,

1393
1:17:50.000 --> 1:17:53.000
Pile就是illusory algebra做的一个数据,

1394
1:17:53.000 --> 1:17:59.000
刚才我也讲到就是一个经过验证或经过考验的数据,

1395
1:17:59.000 --> 1:18:03.000
我们来看一下这个数据集里面其实网页部分,

1396
1:18:03.000 --> 1:18:06.000
就是大家最容易获取到的比如common core这种网页数据,

1397
1:18:06.000 --> 1:18:08.000
在其中占比其实不是很高,

1398
1:18:08.000 --> 1:18:11.000
应该是我记得是不到大概一半左右吧,

1399
1:18:11.000 --> 1:18:13.000
然后剩下都是什么呢?

1400
1:18:13.000 --> 1:18:15.000
比如说像archive大量的文,

1401
1:18:15.000 --> 1:18:17.000
PubMed这种医疗的,

1402
1:18:17.000 --> 1:18:20.000
然后还有一些什么Github,

1403
1:18:20.000 --> 1:18:23.000
然后还有这个stackoverflow,

1404
1:18:23.000 --> 1:18:28.000
就是除了网页之外的所有的这个数据,

1405
1:18:28.000 --> 1:18:31.000
我们几乎在中文上都很难获取到,

1406
1:18:31.000 --> 1:18:34.000
这就导致我们遇到一个困难,

1407
1:18:34.000 --> 1:18:39.000
就是我们可能只用了英文里面所对应的这个集合中很小一部分,

1408
1:18:39.000 --> 1:18:42.000
那剩下的东西我们几乎是很难去找到的,

1409
1:18:42.000 --> 1:18:44.000
而且即使有,

1410
1:18:44.000 --> 1:18:48.000
或其实我们能找到这个数据质量我们其实也很难控制,

1411
1:18:48.000 --> 1:18:52.000
这就导致大家可能只能用一些网页数据去做训练,

1412
1:18:52.000 --> 1:18:54.000
在中文上可能就会有一些问题,

1413
1:18:54.000 --> 1:18:59.000
比如说他不知道一些最新的NLP研究的一些概念,

1414
1:18:59.000 --> 1:19:01.000
这些概念可能只在archive上会有,

1415
1:19:01.000 --> 1:19:03.000
可能国内只是做一些科普,

1416
1:19:03.000 --> 1:19:05.000
核心都在archive上,

1417
1:19:05.000 --> 1:19:06.000
那就没有办法,

1418
1:19:06.000 --> 1:19:10.000
我想问一些比如说跟操作系统相关的一些问题,

1419
1:19:10.000 --> 1:19:13.000
那stack exchange其实就有了,

1420
1:19:13.000 --> 1:19:15.000
所以这其实是一个很危险的一件事情,

1421
1:19:15.000 --> 1:19:19.000
就是说在过去这个数字时代,

1422
1:19:19.000 --> 1:19:22.000
可能中文的数字化是整个是,

1423
1:19:22.000 --> 1:19:24.000
我觉得是偏落后的,

1424
1:19:24.000 --> 1:19:28.000
因为我知道大多数的这个有一定公共经验的工程师,

1425
1:19:28.000 --> 1:19:29.000
可能只会看英文,

1426
1:19:29.000 --> 1:19:31.000
不太会去看中文的信息了,

1427
1:19:31.000 --> 1:19:36.000
这个数字化的落后可能会在大模型时代会被放大,

1428
1:19:36.000 --> 1:19:39.000
那可能大家更倾向于去看英文模型输出结果,

1429
1:19:39.000 --> 1:19:41.000
而不是看中文输出结果,

1430
1:19:41.000 --> 1:19:45.000
所以对一个做中文的算法研究人员来讲的话,

1431
1:19:45.000 --> 1:19:47.000
这件事情可能会变得越来越难。

1432
1:19:47.000 --> 1:19:54.000
OK,这里我其实想到了一个很有趣的一个点,

1433
1:19:54.000 --> 1:19:57.000
就是对这个点是这样,

1434
1:19:57.000 --> 1:20:04.000
那我之前看到一个数据是说所谓整个英文的这个数据量,

1435
1:20:04.000 --> 1:20:06.000
在互联网所有的这个数据量里面,

1436
1:20:06.000 --> 1:20:09.000
它是占59%,

1437
1:20:09.000 --> 1:20:12.000
那中文差不多是占1%,

1438
1:20:12.000 --> 1:20:20.000
那我会理解说这其实是来自于这种英语语言的用户的数量,

1439
1:20:20.000 --> 1:20:26.000
以及说就是英文的国家或者是用户,

1440
1:20:26.000 --> 1:20:30.000
他们更早地开始去开始有这个互联网,

1441
1:20:30.000 --> 1:20:33.000
开始去广泛地在互联网上产生信息,

1442
1:20:33.000 --> 1:20:36.000
包括刚才提到的一些信息,

1443
1:20:36.000 --> 1:20:37.000
一些信息化,

1444
1:20:37.000 --> 1:20:43.000
就是企业的这种数据变成这个信息化的一些内容,

1445
1:20:43.000 --> 1:20:45.000
那这其实都是来自于,

1446
1:20:45.000 --> 1:20:50.000
我会认为这都是来自于第一是足够长的时间窗口,

1447
1:20:50.000 --> 1:20:54.000
然后第二有更多的人来去生产内容,

1448
1:20:54.000 --> 1:20:58.000
那这是一个比较有意思的一个点是说,

1449
1:20:58.000 --> 1:21:05.000
是否在AIGC或者是用模型能够生成数据这件事情上,

1450
1:21:05.000 --> 1:21:11.000
如果它的生成的质量达到某种程度了,

1451
1:21:11.000 --> 1:21:18.000
那因为我们可以理解就是用模型去生产这个信息的速度是会很快的,

1452
1:21:18.000 --> 1:21:22.000
那这两者数据之间的差距,

1453
1:21:22.000 --> 1:21:25.000
它会有缩小的一个趋势吗?

1454
1:21:25.000 --> 1:21:28.000
或者说就是另外一个问题,

1455
1:21:28.000 --> 1:21:32.000
那中文数据占比1%这件事情,

1456
1:21:32.000 --> 1:21:39.000
它是否会因为未来就是中国它也有很好的中文的这种生成的模型,

1457
1:21:39.000 --> 1:21:42.000
所以它能够更快速的生产出一些数据,

1458
1:21:42.000 --> 1:21:45.000
所以这种差距它会变小,

1459
1:21:45.000 --> 1:21:50.000
或者说相对于其他的语言来说中文的这个排名会上升?

1460
1:21:50.000 --> 1:21:55.000
我的观点可能跟你恰好相反吧,

1461
1:21:55.000 --> 1:21:59.000
就是因为不光是中文世界在用模型生产,

1462
1:21:59.000 --> 1:22:02.000
英文世界也会有更好的模型在做生产,

1463
1:22:02.000 --> 1:22:05.000
所以我担心的是两者之间差距会迅速放大,

1464
1:22:05.000 --> 1:22:07.000
而不是说很快逼近,

1465
1:22:07.000 --> 1:22:09.000
再加上我们前面讨论的这个算力的差异,

1466
1:22:09.000 --> 1:22:13.000
导致双方生产成本不一样,

1467
1:22:13.000 --> 1:22:17.000
所以可能我觉得是会变得越来越大的。

1468
1:22:17.000 --> 1:22:20.000
那这里的这个数据差异可不可以,

1469
1:22:20.000 --> 1:22:24.000
因为其实我们看到这个翻译模型现在的能力越来越好,

1470
1:22:24.000 --> 1:22:30.000
有没有可能说我们现阶段用翻译软件先去生成

1471
1:22:30.000 --> 1:22:34.000
批量的生成一些相对低质量的数据,

1472
1:22:34.000 --> 1:22:38.000
然后去弥补我们在中文数据上的短板呢?

1473
1:22:38.000 --> 1:22:41.000
也许一定程度上是能弥补吧,

1474
1:22:41.000 --> 1:22:45.000
但是说实话翻译很多比如说很专业的一些东西,

1475
1:22:45.000 --> 1:22:46.000
其实很难翻译,

1476
1:22:46.000 --> 1:22:50.000
包括不是这个领域的专业人员其实也很难翻译,

1477
1:22:50.000 --> 1:22:52.000
就一篇archive上一篇文章,

1478
1:22:52.000 --> 1:22:54.000
如果你不是做这个领域的很多词,

1479
1:22:54.000 --> 1:22:55.000
每个字母你都认识,

1480
1:22:55.000 --> 1:22:56.000
但你不知道他在说什么,

1481
1:22:56.000 --> 1:22:57.000
对吧?

1482
1:22:57.000 --> 1:22:58.000
这种事其实挺常见的,

1483
1:22:58.000 --> 1:23:00.000
翻译模型有类似的问题,

1484
1:23:00.000 --> 1:23:03.000
我觉得会有一些难。

1485
1:23:03.000 --> 1:23:05.000
我这个有一个非常深的印象,

1486
1:23:05.000 --> 1:23:07.000
就是之前问ChinaDP,

1487
1:23:07.000 --> 1:23:10.000
其实你去问他一些简单的问题,

1488
1:23:10.000 --> 1:23:14.000
包括一些像政治啊或者一些文学方面的东西,

1489
1:23:14.000 --> 1:23:16.000
他其实中文英文都挺好的,

1490
1:23:16.000 --> 1:23:19.000
你跟他说把这个给我转成中文来跟我说,

1491
1:23:19.000 --> 1:23:20.000
这个都蛮不错的,

1492
1:23:20.000 --> 1:23:25.000
但是假设你去问他一个数学证明类的问题,

1493
1:23:25.000 --> 1:23:28.000
他就会像你平常用Wiki一样的那种感觉,

1494
1:23:28.000 --> 1:23:30.000
就是用英文问他,

1495
1:23:30.000 --> 1:23:32.000
然后他给你的资料又全又好,

1496
1:23:32.000 --> 1:23:34.000
而且非常的有逻辑,

1497
1:23:34.000 --> 1:23:35.000
但是你用中文去问他,

1498
1:23:35.000 --> 1:23:37.000
他可能就给你答的莫名其妙,

1499
1:23:37.000 --> 1:23:40.000
然后即便你让他说你用英文给我翻译成中文,

1500
1:23:40.000 --> 1:23:43.000
然后可能在这个翻译过程之中就出问题了,

1501
1:23:43.000 --> 1:23:49.000
就我的感觉是现阶段在中文这边的学术资料,

1502
1:23:49.000 --> 1:23:51.000
真的是差距蛮明显的,

1503
1:23:51.000 --> 1:23:56.000
因为国内其实比较所谓高水平的学术研究,

1504
1:23:56.000 --> 1:23:59.000
也都最后去变成写英文文章了,

1505
1:23:59.000 --> 1:24:03.000
所以这其实是一个挺成问题的事情,

1506
1:24:03.000 --> 1:24:08.000
就相当于他没有办法找到这些专业术语,

1507
1:24:08.000 --> 1:24:13.000
或者一些偏专业的讨论方式的中文版的描述,

1508
1:24:13.000 --> 1:24:17.000
所以这个我觉得可能会很有问题。

1509
1:24:17.000 --> 1:24:21.000
这个问题我还想在演奔问一个问题,

1510
1:24:21.000 --> 1:24:25.000
可能跟刚才欣然说的这个事情也会有关,

1511
1:24:25.000 --> 1:24:28.000
如果我没有记错的话,

1512
1:24:28.000 --> 1:24:31.000
就是GPT-3他当时训练,

1513
1:24:31.000 --> 1:24:35.000
就是预训练的语量的数据是45T,

1514
1:24:35.000 --> 1:24:43.000
对,那这个45T我相信和整个英文互联网的这种信息数据去比的话,

1515
1:24:43.000 --> 1:24:46.000
它是一个非常小的这样的一个子集,

1516
1:24:46.000 --> 1:24:49.000
那这里面就有两个问题,

1517
1:24:49.000 --> 1:24:51.000
就是第一个问题是,

1518
1:24:51.000 --> 1:24:54.000
对于中文来讲,

1519
1:24:54.000 --> 1:25:02.000
为什么我们不能从中文的数据里面也能找出一个45T,

1520
1:25:02.000 --> 1:25:07.000
这么大的一个所谓质量还不错的这样的一个数据,

1521
1:25:07.000 --> 1:25:08.000
然后第二就是,

1522
1:25:08.000 --> 1:25:19.000
为什么这45T它的数量,就是它这么大的一个数据包里面的数据质量就会很好,

1523
1:25:19.000 --> 1:25:22.000
那它好在哪了,

1524
1:25:22.000 --> 1:25:26.000
对,这个想问一下这个龙老师。

1525
1:25:26.000 --> 1:25:30.000
它那个45T其实最后清洗完以后,

1526
1:25:30.000 --> 1:25:31.000
我记得是不到1T的,

1527
1:25:31.000 --> 1:25:33.000
好像500G还是多少,

1528
1:25:33.000 --> 1:25:35.000
反正最后清洗完是不到1G的,

1529
1:25:35.000 --> 1:25:38.000
因为Comcore不管是英文还是中文,

1530
1:25:38.000 --> 1:25:41.000
Comcore的这个数据质量是非常非常差的,

1531
1:25:41.000 --> 1:25:43.000
英文的话我不太好说,

1532
1:25:43.000 --> 1:25:45.000
中文的话基本都是黄土度,

1533
1:25:45.000 --> 1:25:50.000
所以如果你仅仅指望这种Comcore这种网页级别数据的话,

1534
1:25:50.000 --> 1:25:53.000
基本很难训练出一个很好的模型,

1535
1:25:53.000 --> 1:25:57.000
这也是为什么后来无论是GPT Neo,

1536
1:25:57.000 --> 1:25:58.000
还是Bloom,

1537
1:25:58.000 --> 1:26:01.000
还是Meta这几个模型,

1538
1:26:01.000 --> 1:26:07.000
其实都会大比例的加入这些高质量的人工生产内容,

1539
1:26:07.000 --> 1:26:09.000
就刚说的这些论文啊,

1540
1:26:09.000 --> 1:26:10.000
或者说社区问答,

1541
1:26:10.000 --> 1:26:12.000
或者说一些文献,

1542
1:26:12.000 --> 1:26:17.000
这些高质量的内容才是让模型能够达到今天效果的关键,

1543
1:26:17.000 --> 1:26:18.000
这是我的个人观点,

1544
1:26:18.000 --> 1:26:21.000
而互联网内容只是说学会怎么表达,

1545
1:26:21.000 --> 1:26:23.000
我觉得知识性的东西很少,

1546
1:26:23.000 --> 1:26:27.000
就比如说我忘了哪篇那个预算的模型了,

1547
1:26:27.000 --> 1:26:30.000
它会把这个Wiki的权重,

1548
1:26:30.000 --> 1:26:35.000
它可能会在整个数据当中重复两次到三次,

1549
1:26:35.000 --> 1:26:39.000
而这个common core网页数据可能只采用了50%左右,

1550
1:26:39.000 --> 1:26:41.000
所以你也能看出这个倾向性,

1551
1:26:41.000 --> 1:26:43.000
就是说网页数据是不怎么靠谱的,

1552
1:26:43.000 --> 1:26:47.000
这基本上已经是一个广泛认可的观点了,

1553
1:26:47.000 --> 1:26:52.000
所以刚才这个问题可以理解为是,

1554
1:26:52.000 --> 1:26:54.000
首先第一,

1555
1:26:54.000 --> 1:26:56.000
即使在英文世界里面,

1556
1:26:56.000 --> 1:27:01.000
高质量能够用来去训练预算模型的数据,

1557
1:27:01.000 --> 1:27:03.000
其实它也不会很多,

1558
1:27:03.000 --> 1:27:05.000
然后第二,

1559
1:27:05.000 --> 1:27:08.000
可以认为是在中文的领域里面,

1560
1:27:08.000 --> 1:27:13.000
偏知识性的高质量的数据是严重不足的,

1561
1:27:13.000 --> 1:27:14.000
可以这么理解是吗?

1562
1:27:14.000 --> 1:27:16.000
是的,

1563
1:27:16.000 --> 1:27:18.000
我刚刚说对着Pile那张表去看的话,

1564
1:27:18.000 --> 1:27:21.000
最有价值的那部分在中文都很难找到。

1565
1:27:21.000 --> 1:27:23.000
OK。

1566
1:27:23.000 --> 1:27:26.000
好的,其实我们刚刚已经讨论了关于

1567
1:27:26.000 --> 1:27:29.000
大模型训练需要的算力,

1568
1:27:29.000 --> 1:27:30.000
以及基础设施的要求,

1569
1:27:30.000 --> 1:27:33.000
算法当中的一些具体细节,

1570
1:27:33.000 --> 1:27:36.000
以及数据准备环节会遇到的一些问题,

1571
1:27:36.000 --> 1:27:40.000
那现在其实回到一些最关键的问题就是,

1572
1:27:40.000 --> 1:27:43.000
我们要去进行一个大语言模型的训练,

1573
1:27:43.000 --> 1:27:46.000
我们这个团队需要具备哪些人,

1574
1:27:46.000 --> 1:27:53.000
这些人需要具备什么样的能力呢?

1575
1:27:53.000 --> 1:27:54.000
我先起个头,

1576
1:27:54.000 --> 1:27:57.000
然后看看各位有没有补充,

1577
1:27:57.000 --> 1:28:03.000
其实这个我是先去会考虑先去观察这个BigScience,

1578
1:28:03.000 --> 1:28:04.000
Handicap这个项目,

1579
1:28:04.000 --> 1:28:06.000
这个项目的这个人员配置,

1580
1:28:06.000 --> 1:28:08.000
因为无论是OpenAI,

1581
1:28:08.000 --> 1:28:10.000
我们只说这些最大的OpenAI,

1582
1:28:10.000 --> 1:28:11.000
以及Meta,

1583
1:28:11.000 --> 1:28:13.000
他们的这个论文虽然有,

1584
1:28:13.000 --> 1:28:15.000
但是他们的人员配置其实不是那么透明的,

1585
1:28:15.000 --> 1:28:18.000
我们很难清楚里面的人是干什么的,

1586
1:28:18.000 --> 1:28:19.000
而BigScience这个整个项目,

1587
1:28:19.000 --> 1:28:22.000
从头到尾每一个人的身份都是很明确的,

1588
1:28:22.000 --> 1:28:24.000
大家也能看到这些人是怎么分工的,

1589
1:28:24.000 --> 1:28:28.000
包括他们每一次的每周的周会也都有录像的,

1590
1:28:28.000 --> 1:28:31.000
所以根据BigScience的经验的话,

1591
1:28:31.000 --> 1:28:34.000
其实你会总结出几种类型的人,

1592
1:28:34.000 --> 1:28:36.000
一种就是说大数据的工程师,

1593
1:28:36.000 --> 1:28:37.000
可能偏数据工作,

1594
1:28:37.000 --> 1:28:39.000
因为涉及到大量数据的预处理,

1595
1:28:39.000 --> 1:28:44.000
然后这里面在数据这块还有一些偏法务的一些人,

1596
1:28:44.000 --> 1:28:47.000
就可能观察一下比如我们数据的license是否合理,

1597
1:28:47.000 --> 1:28:52.000
所以数据这块大概就是大数据工程师加少量的法务人员,

1598
1:28:52.000 --> 1:28:56.000
然后剩下就是大量这种NLP算法工程师,

1599
1:28:56.000 --> 1:28:58.000
大量可能也不会说超过10,

1600
1:28:58.000 --> 1:29:02.000
他们可能更关心比如说我要选一个什么样的模型架构,

1601
1:29:02.000 --> 1:29:07.000
以及在训练当中所有的这些超参的选项,

1602
1:29:07.000 --> 1:29:10.000
这个可能在两年前是一件很重要的事情,

1603
1:29:10.000 --> 1:29:12.000
但在今年去看的话,

1604
1:29:12.000 --> 1:29:14.000
大家基本都认可了OpenAI这个设定的话,

1605
1:29:14.000 --> 1:29:16.000
算法工程师可能并不需要那么多了,

1606
1:29:16.000 --> 1:29:18.000
只是说去解读一下论文,

1607
1:29:18.000 --> 1:29:20.000
然后去把它实现出来,

1608
1:29:20.000 --> 1:29:23.000
所以这部分人可能会少一些,

1609
1:29:23.000 --> 1:29:25.000
我猜应该不到5就够了,

1610
1:29:25.000 --> 1:29:27.000
然后就是说训练这块,

1611
1:29:27.000 --> 1:29:30.000
训练这块人可能就是说做一些分布式系统的,

1612
1:29:30.000 --> 1:29:33.000
有一些分布式系统经验,

1613
1:29:33.000 --> 1:29:36.000
然后怎么把这个训练框架给支起来,

1614
1:29:36.000 --> 1:29:39.000
然后怎么搞定这么多机器去协调的,

1615
1:29:39.000 --> 1:29:43.000
去做运维,去做管理,

1616
1:29:43.000 --> 1:29:47.000
这块可能是有一些算法的经验在里面,

1617
1:29:47.000 --> 1:29:49.000
但可能更多是系统管理,

1618
1:29:49.000 --> 1:29:51.000
以及软件开发的一些经验,

1619
1:29:51.000 --> 1:29:54.000
然后可能还需要少量的前后端开发,

1620
1:29:54.000 --> 1:29:57.000
我们前面讲到OpenAI做的Instructable T,

1621
1:29:57.000 --> 1:30:00.000
其实它们有很多的工具在里面,

1622
1:30:00.000 --> 1:30:02.000
尤其是数据的工具,

1623
1:30:02.000 --> 1:30:05.000
这里面其实是需要一些前后端开发工作的,

1624
1:30:05.000 --> 1:30:10.000
然后也包括像之前T0做的RAMSource那种工具,

1625
1:30:10.000 --> 1:30:15.000
所以前后端开发我猜也会需要1到2个人,

1626
1:30:15.000 --> 1:30:17.000
大概这么一个配置,

1627
1:30:17.000 --> 1:30:20.000
大家看有没有什么补充?

1628
1:30:23.000 --> 1:30:26.000
我这边的感觉就是,

1629
1:30:26.000 --> 1:30:29.000
很多人觉得说我要训练一个大模型,

1630
1:30:29.000 --> 1:30:33.000
就像传统的一些比较大的项目,

1631
1:30:33.000 --> 1:30:35.000
我要堆一大堆的人,

1632
1:30:35.000 --> 1:30:37.000
但其实像ChartTBG这一类的东西,

1633
1:30:37.000 --> 1:30:41.000
它最大的特点其实就是极少量的idea,

1634
1:30:41.000 --> 1:30:45.000
要指挥的动极大的一个资源,

1635
1:30:45.000 --> 1:30:48.000
所以我会觉得比较重要的其实就是,

1636
1:30:48.000 --> 1:30:52.000
一个算法的角色,

1637
1:30:52.000 --> 1:30:55.000
这个算法的角色指挥着所有人去做,

1638
1:30:55.000 --> 1:30:57.000
那相应的可能像刚才提到的说,

1639
1:30:57.000 --> 1:30:59.000
有数据团队,工程团队,

1640
1:30:59.000 --> 1:31:01.000
这些人去支撑这件事,

1641
1:31:01.000 --> 1:31:05.000
所以相当可怕的一件事情就是堆一大堆人,

1642
1:31:05.000 --> 1:31:08.000
这一大堆人相互争权奪利,

1643
1:31:08.000 --> 1:31:10.000
不断地相互challenge,

1644
1:31:10.000 --> 1:31:14.000
把一大份资源切成四五份去分别用,

1645
1:31:14.000 --> 1:31:16.000
这个将会是一个最可怕的事情,

1646
1:31:16.000 --> 1:31:20.000
所以把人员的精简是非常重要的一件事情。

1647
1:31:22.000 --> 1:31:25.000
我觉得这是一个挺有意思的点,

1648
1:31:25.000 --> 1:31:28.000
那我们觉得从我们需要的人力资源,

1649
1:31:28.000 --> 1:31:32.000
和整个团队的效率来考虑,

1650
1:31:32.000 --> 1:31:37.000
大概多大的一个团队是一个比较好的规模呢?

1651
1:31:40.000 --> 1:31:46.000
这个问题是不是可以直接就参考OpenAI它的一个配置?

1652
1:31:46.000 --> 1:31:47.000
我觉得不太能参考,

1653
1:31:47.000 --> 1:31:50.000
因为我们说实话OpenAI是远远在前面的,

1654
1:31:50.000 --> 1:31:53.000
我们剩下包括不光是中国,

1655
1:31:53.000 --> 1:31:56.000
其他所有公司都是只是一个追随者,

1656
1:31:56.000 --> 1:31:59.000
那在追随者的身份上其实需要的人会更少,

1657
1:31:59.000 --> 1:32:00.000
尤其在算法上,

1658
1:32:00.000 --> 1:32:04.000
因为对我们来讲它那篇paper其实都不能叫paper,

1659
1:32:04.000 --> 1:32:09.000
叫算法文档,或使用文档,

1660
1:32:09.000 --> 1:32:12.000
我们说的文档能够模仿出来这件事情,

1661
1:32:12.000 --> 1:32:15.000
对其他所有公司来说已经是一件很难的事情了,

1662
1:32:15.000 --> 1:32:19.000
所以我觉得人力规模应该不太需要超过十个人。

1663
1:32:21.000 --> 1:32:22.000
靳远你继续。

1664
1:32:22.000 --> 1:32:28.000
我觉得有一个点可能需要看国情考虑,

1665
1:32:28.000 --> 1:32:29.000
OpenAI这边做的时候,

1666
1:32:29.000 --> 1:32:35.000
其实它有相当多的人力和困难都交给了它的下游,

1667
1:32:35.000 --> 1:32:38.000
或者应该称之为上游吧,

1668
1:32:38.000 --> 1:32:40.000
比如说它的显卡或者它的集群资源

1669
1:32:40.000 --> 1:32:42.000
其实是从微软这边租过来的,

1670
1:32:42.000 --> 1:32:46.000
比如它的数据其实是大量的动用到外面的人员来帮忙做的,

1671
1:32:46.000 --> 1:32:50.000
就这些部分其实在国内会是一个比较尴尬的问题,

1672
1:32:50.000 --> 1:32:56.000
就是如果要是去采购别的公司,

1673
1:32:56.000 --> 1:32:58.000
现在国内竞争如此严重的情况下,

1674
1:32:58.000 --> 1:33:01.000
会发现这些供应商很有可能会成为

1675
1:33:01.000 --> 1:33:03.000
整个事情最困难的那一部分,

1676
1:33:03.000 --> 1:33:05.000
你采的数据可能会流到别人手里,

1677
1:33:05.000 --> 1:33:07.000
等等大家会有不同的竞争,

1678
1:33:07.000 --> 1:33:10.000
所以我不知道在国内如果做这件事情的话,

1679
1:33:10.000 --> 1:33:13.000
会不会变成数据团队,

1680
1:33:13.000 --> 1:33:17.000
整个集群管理等等又自己重新做一遍,

1681
1:33:17.000 --> 1:33:22.000
我觉得这个可能会是人员规模的一个重大影响因素,

1682
1:33:22.000 --> 1:33:25.000
至于具体的真正我说指导几个人去训练模型,

1683
1:33:25.000 --> 1:33:29.000
去维护整个分布式系统的可靠,

1684
1:33:29.000 --> 1:33:31.000
这些反而用的人可能非常少,

1685
1:33:31.000 --> 1:33:33.000
我猜四五个人就够了。

1686
1:33:33.000 --> 1:33:39.000
了解了,今天我们其实已经从算力算法工程数据人的角度

1687
1:33:39.000 --> 1:33:43.000
去讨论了如何训练一个千亿量级的大预约模型,

1688
1:33:43.000 --> 1:33:49.000
那今天各位嘉宾有什么自己特别想对另一位嘉宾提的问题吗?

1689
1:33:49.000 --> 1:33:52.000
我先来吧,

1690
1:33:52.000 --> 1:33:55.000
我这边有一个问题,

1691
1:33:55.000 --> 1:33:57.000
我这边来问,

1692
1:33:57.000 --> 1:33:59.000
其实这个欣然跟老师都可以,

1693
1:33:59.000 --> 1:34:01.000
你们俩看谁合适回答,

1694
1:34:01.000 --> 1:34:06.000
就是这个是关于模型训练底层工具的,

1695
1:34:06.000 --> 1:34:12.000
因为我们会说像模型训练底层工具,

1696
1:34:12.000 --> 1:34:14.000
就是像开源框架,

1697
1:34:14.000 --> 1:34:20.000
它其实是各种算法生产的一个非常底层的工具,

1698
1:34:20.000 --> 1:34:26.000
那我的问题是对于transformer这种架构来讲,

1699
1:34:26.000 --> 1:34:33.000
那未来有没有可能会出现一个专有的这样的一个框架,

1700
1:34:33.000 --> 1:34:37.000
就是它就是对transformer训练起来很爽,

1701
1:34:37.000 --> 1:34:41.000
或者说在这样一个框架基础之上,

1702
1:34:41.000 --> 1:34:48.000
它可能会长出像能非常好的去非常方便的去训练chat的GPT,

1703
1:34:48.000 --> 1:34:51.000
这样就是带instructor tuning,

1704
1:34:51.000 --> 1:34:53.000
再加一个训练模型,

1705
1:34:53.000 --> 1:34:55.000
再加一个reward model,

1706
1:34:55.000 --> 1:34:58.000
这样一套系统的这种工具,

1707
1:34:58.000 --> 1:35:02.000
它会出现,或者是需要吗?

1708
1:35:05.000 --> 1:35:07.000
这个我先来吧,

1709
1:35:07.000 --> 1:35:12.000
我理解在不同的层面上这件事其实就已经出现,

1710
1:35:12.000 --> 1:35:15.000
就比如说前面反复在提到的megatron,

1711
1:35:15.000 --> 1:35:23.000
其实这个东西就是因为他们这边觉得transformer是下一个时代,

1712
1:35:23.000 --> 1:35:29.000
所以要做这么一个工具去帮助你很快地去做分布式的训练,

1713
1:35:29.000 --> 1:35:31.000
如果没有megatron这个工具的话,

1714
1:35:31.000 --> 1:35:38.000
其实现在绝大多数在号称自己做GPT训练的人应该都搞不出来,

1715
1:35:38.000 --> 1:35:45.000
因为有能力从头搭建一个这种知道模型背景怎么切分,

1716
1:35:45.000 --> 1:35:47.000
怎么高效地利用显卡,

1717
1:35:47.000 --> 1:35:50.000
怎么把各种事情都处理得非常好,

1718
1:35:50.000 --> 1:35:53.000
能够把通信跟计算都overlap得非常好,

1719
1:35:53.000 --> 1:35:57.000
是我觉得国内没有几个团队能做得出来的这个事情,

1720
1:35:57.000 --> 1:36:00.000
所以其实这样的框架已经出来了,

1721
1:36:00.000 --> 1:36:01.000
而且很多,

1722
1:36:01.000 --> 1:36:05.000
就刚才也提到了微软还在基础上去改这些东西,

1723
1:36:05.000 --> 1:36:08.000
国外也有一些创业公司在做,

1724
1:36:08.000 --> 1:36:14.000
有没有可能会有人把它慢慢地做得像stable diffusion一样,

1725
1:36:14.000 --> 1:36:17.000
就是我搞成一个非常开箱机用的工具,

1726
1:36:17.000 --> 1:36:20.000
就定向是做chart GPT的,

1727
1:36:20.000 --> 1:36:23.000
我估计慢慢地肯定会出来的,

1728
1:36:23.000 --> 1:36:26.000
只是它的集成度不一定那么高,

1729
1:36:26.000 --> 1:36:31.000
毕竟这个事儿现在还没有把它的这个应用程度降低到说,

1730
1:36:31.000 --> 1:36:34.000
可能我随便弄几块显卡就可以搞定,

1731
1:36:34.000 --> 1:36:36.000
所以应该不会那么易用,

1732
1:36:36.000 --> 1:36:38.000
但是一定会有人慢慢做出来。

1733
1:36:42.000 --> 1:36:44.000
对,龙老师有什么观点?

1734
1:36:46.000 --> 1:36:48.000
我觉得可能会有两拨人吧,

1735
1:36:48.000 --> 1:36:49.000
我比较看好两拨,

1736
1:36:49.000 --> 1:36:52.000
一拨就是说刚才欣然说的这个,

1737
1:36:52.000 --> 1:36:54.000
因为大家肯定会参与其中,

1738
1:36:54.000 --> 1:36:58.000
然后去推动这个框架和它的这个硬件的绑定程度,

1739
1:36:58.000 --> 1:37:00.000
这他们肯定要做的,

1740
1:37:00.000 --> 1:37:01.000
比如microchrome做一些改进,

1741
1:37:01.000 --> 1:37:06.000
然后另外一个需要观察的就是Hardinface最近和AWS合作,

1742
1:37:06.000 --> 1:37:11.000
那他们其实是做框架或做这种易用性框架的一个好手,

1743
1:37:11.000 --> 1:37:15.000
那他们肯定会在这方面去有所推进,

1744
1:37:15.000 --> 1:37:17.000
其实他们推进速度已经低于我预期了,

1745
1:37:17.000 --> 1:37:20.000
但可能是一直在等一些机会吧,

1746
1:37:20.000 --> 1:37:23.000
然后他们也在这方面其实已经储备了很多资源,

1747
1:37:23.000 --> 1:37:26.000
比如说现在大家常用Transformer框架用它的,

1748
1:37:26.000 --> 1:37:28.000
虽然都是一些小模型了,

1749
1:37:28.000 --> 1:37:30.000
然后包括训练加速,

1750
1:37:30.000 --> 1:37:31.000
推理加速,

1751
1:37:31.000 --> 1:37:35.000
以及他们在强化学习最近半年做了大量这种课程,

1752
1:37:35.000 --> 1:37:37.000
我猜都是在做一些储备,

1753
1:37:37.000 --> 1:37:40.000
所以我猜未来可能就是说小规模的训练,

1754
1:37:40.000 --> 1:37:42.000
大家会用Hardinface新出一个什么样的框架,

1755
1:37:42.000 --> 1:37:47.000
然后大规模训练用microchrome这边或者英伟达这边新出一个什么框架,

1756
1:37:47.000 --> 1:37:49.000
我是这么猜测的。

1757
1:37:49.000 --> 1:37:51.000
其实我还有一个预测,

1758
1:37:51.000 --> 1:37:59.000
我觉得英伟达其实很早之前就往Transformer这件事上已经压住压得非常的明显了,

1759
1:37:59.000 --> 1:38:02.000
它其实是把整个Transformer这些特定的结构,

1760
1:38:02.000 --> 1:38:06.000
现在直接做到了它所谓比较号称通用性的这种芯片里面,

1761
1:38:06.000 --> 1:38:08.000
也就是说从H100开始,

1762
1:38:08.000 --> 1:38:13.000
芯片里面直接就有为Transformer专门设计的这些集成链,

1763
1:38:13.000 --> 1:38:20.000
整个英伟达在最近这三四年往Transformer不管是这种研发,

1764
1:38:20.000 --> 1:38:24.000
就是软件研发去给你做好用的Depression,

1765
1:38:24.000 --> 1:38:26.000
好用的这种绘图的软件,

1766
1:38:26.000 --> 1:38:28.000
好用的Transformer这些层面,

1767
1:38:28.000 --> 1:38:29.000
还是硬件的层面,

1768
1:38:29.000 --> 1:38:31.000
它都在一直在努力,

1769
1:38:31.000 --> 1:38:33.000
所以我这其实可以做一个预测,

1770
1:38:33.000 --> 1:38:36.000
如果英伟达没有这种特定的结构,

1771
1:38:36.000 --> 1:38:38.000
它就会在这种软件上,

1772
1:38:38.000 --> 1:38:43.000
它就会一直在努力,

1773
1:38:43.000 --> 1:38:46.000
如果英伟达没有做一些降制操作的话,

1774
1:38:46.000 --> 1:38:51.000
那很有可能在未来三年到五年之内,

1775
1:38:51.000 --> 1:38:57.000
英伟达会去希望把整个Transformer的小规模的训练,

1776
1:38:57.000 --> 1:39:01.000
可能能做到单机,

1777
1:39:01.000 --> 1:39:03.000
就是8卡可以搞定的这种程度,

1778
1:39:03.000 --> 1:39:06.000
我觉得这是一个非常有可能的事情,

1779
1:39:06.000 --> 1:39:08.000
在这种情况下英伟达就非常有动力,

1780
1:39:08.000 --> 1:39:10.000
去给你做一个非常好用的工具,

1781
1:39:10.000 --> 1:39:12.000
让人人都能做,

1782
1:39:12.000 --> 1:39:17.000
我觉得这是一个非常有现实的商业战略。

1783
1:39:20.000 --> 1:39:24.000
了解了,那龙老师和兴南有什么问题吗?

1784
1:39:26.000 --> 1:39:28.000
其实我,

1785
1:39:28.000 --> 1:39:30.000
龙老师先来吧,

1786
1:39:30.000 --> 1:39:32.000
那我先,

1787
1:39:32.000 --> 1:39:34.000
我这边其实有一个问题,

1788
1:39:34.000 --> 1:39:37.000
就是现在Charta GPT这么这么的火,

1789
1:39:37.000 --> 1:39:39.000
那我其实很好奇,

1790
1:39:39.000 --> 1:39:42.000
从投资人的视角来看来,

1791
1:39:42.000 --> 1:39:46.000
为什么要这么往死里炒这个Charta GPT,

1792
1:39:46.000 --> 1:39:50.000
尤其是为什么这么在意每个人都要训练出Charta GPT,

1793
1:39:50.000 --> 1:39:53.000
这是一个我非常疑惑的一个问题,

1794
1:39:53.000 --> 1:39:57.000
这件事真的是一个从投资人视角看来,

1795
1:39:57.000 --> 1:40:00.000
它合乎逻辑的投资吗?

1796
1:40:00.000 --> 1:40:04.000
这个问题我说说个人的观点,

1797
1:40:04.000 --> 1:40:06.000
不代表机构,

1798
1:40:06.000 --> 1:40:09.000
首先我觉得大学模型所学习的人类知识,

1799
1:40:09.000 --> 1:40:12.000
以及Charta GPT所提供的交互模式,

1800
1:40:12.000 --> 1:40:16.000
创造了一种全新的人际交互界面,

1801
1:40:16.000 --> 1:40:20.000
那我们回顾科技过去30年的发展历史,

1802
1:40:20.000 --> 1:40:24.000
会发现浏览器的诞生和智能机的出现,

1803
1:40:24.000 --> 1:40:28.000
分别都创造了一种新的人际交互界面,

1804
1:40:28.000 --> 1:40:32.000
它大大提高了人类社会对于信息的获取,

1805
1:40:32.000 --> 1:40:34.000
检索和利用的效率,

1806
1:40:34.000 --> 1:40:37.000
都带来了一波平台性的范式转移,

1807
1:40:37.000 --> 1:40:40.000
今天让我特别兴奋的一点,

1808
1:40:40.000 --> 1:40:45.000
第一当然是大学模型本身所表现出的学习推理能力,

1809
1:40:45.000 --> 1:40:50.000
让我对人工智能未来的发展潜力有了更大的期待,

1810
1:40:50.000 --> 1:40:55.000
第二是我认为在这种新的人际交互界面的加持下,

1811
1:40:55.000 --> 1:41:01.000
人类社会的信息获取,信息检索,

1812
1:41:01.000 --> 1:41:03.000
信息利用,内容生产,

1813
1:41:03.000 --> 1:41:08.000
以及知识的再创造都会经历一波非常大的平台性机会。

1814
1:41:09.000 --> 1:41:15.000
我觉得我可以从产品或者市场的角度来做一个补充,

1815
1:41:15.000 --> 1:41:18.000
我觉得第二个问题,

1816
1:41:18.000 --> 1:41:24.000
就是为什么大家要去追国内的OpenAI或者是ChartGBT,

1817
1:41:24.000 --> 1:41:30.000
因为这件事情相比于ChartGBT上层的应用,

1818
1:41:30.000 --> 1:41:34.000
或者是一些工具型产品,

1819
1:41:34.000 --> 1:41:35.000
或者是开源项目,

1820
1:41:35.000 --> 1:41:38.000
开源的这种公司来去比的话,

1821
1:41:38.000 --> 1:41:42.000
它的确定性是更高的,

1822
1:41:42.000 --> 1:41:43.000
或者是最高的,

1823
1:41:43.000 --> 1:41:44.000
什么意思呢?

1824
1:41:44.000 --> 1:41:46.000
其实就是刚才KWay有提到,

1825
1:41:46.000 --> 1:41:49.000
大家都很明确的一件事情,

1826
1:41:49.000 --> 1:41:56.000
就是中国它一定需要一个自己的这样的一个大模型,

1827
1:41:56.000 --> 1:41:58.000
所以不管是谁,

1828
1:41:58.000 --> 1:42:03.000
肯定是有那么一家或者是几家它会出来,

1829
1:42:03.000 --> 1:42:08.000
但是上面比如说像去做开源的工具的,

1830
1:42:08.000 --> 1:42:13.000
或者说是一些所谓中间层以及应用层的这种公司,

1831
1:42:13.000 --> 1:42:15.000
那可就不一定了,

1832
1:42:15.000 --> 1:42:17.000
就是比如开源的项目,

1833
1:42:17.000 --> 1:42:20.000
国内国外它是更互通的,

1834
1:42:20.000 --> 1:42:22.000
那应用层来讲的话,

1835
1:42:22.000 --> 1:42:25.000
你不管是去做2B的这种SaaS,

1836
1:42:25.000 --> 1:42:27.000
还是去做一些2C的产品,

1837
1:42:27.000 --> 1:42:30.000
现在它都有非常高的不确定性,

1838
1:42:30.000 --> 1:42:33.000
所以从投资人的逻辑来讲的话,

1839
1:42:33.000 --> 1:42:37.000
可能就是要找一个非常确定的事情。

1840
1:42:37.000 --> 1:42:43.000
其实我有一个问题是想问所有人,

1841
1:42:43.000 --> 1:42:44.000
因为大家背景不一样,

1842
1:42:44.000 --> 1:42:48.000
所以我想通过大家的回答去sample出一个结果,

1843
1:42:48.000 --> 1:42:52.000
就是在中国的这个市场下,

1844
1:42:52.000 --> 1:42:55.000
半年或一年之后,

1845
1:42:55.000 --> 1:42:58.000
会只有一个China GPT类似产品,

1846
1:42:58.000 --> 1:43:01.000
还是会有多个China GPT类似产品,

1847
1:43:01.000 --> 1:43:05.000
就像云还是操作系统一样?

1848
1:43:05.000 --> 1:43:08.000
对,要不我先说说我的一些看法吧,

1849
1:43:08.000 --> 1:43:12.000
首先我觉得中国的大模型市场

1850
1:43:12.000 --> 1:43:15.000
会跟美国有一个很大的差异,

1851
1:43:15.000 --> 1:43:18.000
这个一个核心的差异点可能来自于

1852
1:43:18.000 --> 1:43:22.000
中国现在大量业务的公有云化程度

1853
1:43:22.000 --> 1:43:24.000
其实是低于美国的,

1854
1:43:24.000 --> 1:43:28.000
而且中国在各种数据监管

1855
1:43:28.000 --> 1:43:31.000
以及企业的一些惯性的情况下

1856
1:43:31.000 --> 1:43:38.000
会导致很多在美国的一些2B和2C的服务

1857
1:43:38.000 --> 1:43:43.000
没有办法在中国用公有云的形式来提供,

1858
1:43:43.000 --> 1:43:48.000
这就会导致大量的大模型商业化的市场

1859
1:43:48.000 --> 1:43:51.000
可能会在一些2B的私有云端,

1860
1:43:51.000 --> 1:43:58.000
这就会导致头部的垄断的可能性会没有那么大,

1861
1:43:58.000 --> 1:44:01.000
但是同时又会看到如果说接下来会有一家

1862
1:44:01.000 --> 1:44:06.000
类似于像OpenAI提供China GPT和GPT3

1863
1:44:06.000 --> 1:44:08.000
这种公有云的模式的话,

1864
1:44:08.000 --> 1:44:12.000
其实可能云厂商会有一个非常强的优势,

1865
1:44:12.000 --> 1:44:16.000
原因就在于其实目前我们看到大模型

1866
1:44:16.000 --> 1:44:19.000
它对于influence的整个算力要求还是非常高的,

1867
1:44:19.000 --> 1:44:23.000
那么一些没有自有算力的一些小厂商

1868
1:44:23.000 --> 1:44:26.000
它可能在公有云的这个场景下面

1869
1:44:26.000 --> 1:44:32.000
就会远不如大厂有这个可烧的钱和成本优势

1870
1:44:32.000 --> 1:44:35.000
去做这个市场的这个占有,

1871
1:44:35.000 --> 1:44:38.000
所以可能接下来的生态我觉得会有这个

1872
1:44:38.000 --> 1:44:42.000
头部的两三家公有云厂商去提供一个

1873
1:44:42.000 --> 1:44:47.000
大云模型的这个API和其他的公有云服务,

1874
1:44:47.000 --> 1:44:53.000
而有多家这些厂商能够去提供2B的

1875
1:44:53.000 --> 1:44:55.000
这个私有云端的一个服务,

1876
1:44:55.000 --> 1:44:58.000
这个可能是我的一个预测,对。

1877
1:44:59.000 --> 1:45:01.000
OK,那我来说一下,

1878
1:45:01.000 --> 1:45:06.000
对,就是我跟Keyway的这个观点基本上是一致的,

1879
1:45:06.000 --> 1:45:10.000
但是我会认为这件事情它可能也不光是

1880
1:45:10.000 --> 1:45:13.000
国内的一个现状,对,

1881
1:45:13.000 --> 1:45:17.000
包括之前这个Sam Altman他也提出过说

1882
1:45:17.000 --> 1:45:20.000
他会认为未来整个大模型这个行业

1883
1:45:20.000 --> 1:45:24.000
除了我们现在看到的就是像OpenAI这样

1884
1:45:24.000 --> 1:45:28.000
去做底层基础模型服务的这个基建层之外,

1885
1:45:28.000 --> 1:45:34.000
以及上面直接包这个OpenAI的API去做应用的

1886
1:45:34.000 --> 1:45:38.000
这个企业之外,可能还会有一个很厚的一个中间层,

1887
1:45:38.000 --> 1:45:41.000
然后像这个中间层里面可能会包含的一种角色

1888
1:45:41.000 --> 1:45:47.000
就是非常多的垂直场景的预训模型,对,

1889
1:45:47.000 --> 1:45:52.000
那这件事情我会认为它在国内的发展的趋势

1890
1:45:52.000 --> 1:45:57.000
相对会更乐观或者说是更符合它的这个预期,

1891
1:45:57.000 --> 1:46:03.000
为什么呢?我们从CV这个时代的一些发展趋势

1892
1:46:03.000 --> 1:46:07.000
其实就能够看到一个现象,

1893
1:46:07.000 --> 1:46:13.000
就是很多的这种技术国外它代表的是这个高度,

1894
1:46:13.000 --> 1:46:19.000
然后这个中国它就反而代表的是这个技术应用的一个深度,

1895
1:46:19.000 --> 1:46:25.000
这个其实有一个非常底层的逻辑是在于怎么描述呢?

1896
1:46:25.000 --> 1:46:28.000
我觉得可能是叫体制优势,

1897
1:46:28.000 --> 1:46:31.000
就是所谓的统筹规划能力,

1898
1:46:31.000 --> 1:46:39.000
对,比如这个很多这种大企业都需要开始拥抱所谓大模型了,

1899
1:46:39.000 --> 1:46:43.000
那这件事情它会很快的就去做一个应用的普及,

1900
1:46:43.000 --> 1:46:47.000
那在这样一个应用普及的这个过程中,

1901
1:46:47.000 --> 1:46:51.000
它势必是会有个性化的一个需求的,

1902
1:46:51.000 --> 1:46:58.000
那这些个性化的需求如果它没有办法在基础这个模型层一一得到满足,

1903
1:46:58.000 --> 1:47:04.000
那它可能就需要有一些更定制化的这样的一些算法出来,

1904
1:47:04.000 --> 1:47:10.000
那这个时候其实就会是一个这个中间层他们来去做的事情,

1905
1:47:10.000 --> 1:47:13.000
以及因为你刚才提到了一个时间点,

1906
1:47:13.000 --> 1:47:15.000
就是半年,

1907
1:47:15.000 --> 1:47:18.000
我觉得半年这个时间点可能会稍微有些短,

1908
1:47:18.000 --> 1:47:25.000
因为目前我们处在的是一个叫这个千模大战或者是百模大战的这样的一个阶段,

1909
1:47:25.000 --> 1:47:28.000
那这个阶段它势必会带来一个结果,

1910
1:47:28.000 --> 1:47:31.000
就是最终有少数企业会跑出来,

1911
1:47:31.000 --> 1:47:35.000
那没有跑出来的这些企业或者是组织他们的人,

1912
1:47:35.000 --> 1:47:38.000
大家其实都是会去大模型的,

1913
1:47:38.000 --> 1:47:43.000
那这些人他在市场上面其实会形成一个很强的这种技术的外溢,

1914
1:47:43.000 --> 1:47:49.000
或者说是在一些非大模型行业里面的一个渗透,

1915
1:47:49.000 --> 1:47:54.000
那这个时候其实就会有一个很有趣的这样的一个市场现象,

1916
1:47:54.000 --> 1:47:56.000
我们不妨拭目以待。

1917
1:48:00.000 --> 1:48:04.000
欣然对这个问题有自己的看法吗?

1918
1:48:06.000 --> 1:48:08.000
我觉得没有什么,

1919
1:48:08.000 --> 1:48:12.000
就我在这一块现在没有什么能想象的出来的东西,

1920
1:48:12.000 --> 1:48:18.000
我觉得大模型很难预测它半年之后的样子,

1921
1:48:18.000 --> 1:48:21.000
因为有可能三个月之后突然大家发现,

1922
1:48:21.000 --> 1:48:23.000
诶,ChatterDB不本质,

1923
1:48:23.000 --> 1:48:26.000
就是突然谁要发一篇什么样的文章,

1924
1:48:26.000 --> 1:48:32.000
所以我觉得现阶段去预测这些东西是不太有效的,

1925
1:48:32.000 --> 1:48:37.000
很有可能会发生说过了半年之后大家发现,

1926
1:48:37.000 --> 1:48:40.000
诶,其实我们需要的又不是这样的大模型,

1927
1:48:40.000 --> 1:48:42.000
可能要做别的样子的,

1928
1:48:42.000 --> 1:48:44.000
这个我觉得不太好说。

1929
1:48:46.000 --> 1:48:48.000
对,确实这我们,

1930
1:48:48.000 --> 1:48:50.000
确实是一个非常好的一个Point,

1931
1:48:50.000 --> 1:48:57.000
就是我们也很期待接下来这个GPT4发布会是一个什么样的模型。

1932
1:48:58.000 --> 1:49:02.000
好的,今天非常感谢各位嘉宾宝贵的经验和真挚着见,

1933
1:49:02.000 --> 1:49:05.000
其实自去年11月底Chai GPT发布以来,

1934
1:49:05.000 --> 1:49:07.000
大模型的热度持续发酵,

1935
1:49:07.000 --> 1:49:11.000
相信高物件里的讨论听众朋友们已经看了很多了,

1936
1:49:11.000 --> 1:49:14.000
所以我们今天选择从Practical的角度,

1937
1:49:14.000 --> 1:49:18.000
分别就算力,算法,工程,数据和团队,

1938
1:49:18.000 --> 1:49:23.000
讨论了训练一个千亿参数量级的大语言模型和Chai GPT需要些什么,

1939
1:49:23.000 --> 1:49:29.000
希望能够给一些正在尝试拥抱大模型的业务决策者和技术人员一些有价值的参考。

1940
1:49:29.000 --> 1:49:34.000
我们相信,一个千亿参数的大语言模型并不是终点,

1941
1:49:34.000 --> 1:49:36.000
而只是AI浪潮中的第一步,

1942
1:49:36.000 --> 1:49:40.000
开放的分享和讨论才能加速整个生态的发展和落地。

1943
1:49:40.000 --> 1:49:42.000
在接下来的几期博客中,

1944
1:49:42.000 --> 1:49:47.000
我们将继续讨论大语言模型的算法、工具和应用等话题,

1945
1:49:47.000 --> 1:49:50.000
也欢迎更多的小伙伴能够加入我们,

1946
1:49:50.000 --> 1:49:53.000
在人工智能大潮中一起仰望星空,

1947
1:49:53.000 --> 1:50:07.000
也一起脚踏实地的前行。

